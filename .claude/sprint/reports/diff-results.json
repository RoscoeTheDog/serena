{
  "merge_base": "aa8c5c6ff6dc5f0bba45acb20be145d37e94b3dc",
  "target_files": {
    "src/serena/config/context_mode.py": "M",
    "src/serena/config/serena_config.py": "M",
    "src/serena/project.py": "M",
    "src/serena/tools/cmd_tools.py": "M",
    "src/serena/tools/config_tools.py": "M",
    "src/serena/tools/file_tools.py": "M",
    "src/serena/tools/jetbrains_plugin_client.py": "M",
    "src/serena/tools/jetbrains_tools.py": "M",
    "src/serena/tools/memory_tools.py": "M",
    "src/serena/tools/symbol_tools.py": "M",
    "src/serena/tools/tools_base.py": "M",
    "src/serena/tools/workflow_tools.py": "M"
  },
  "conflicts_found": true,
  "file_diffs": {
    "src/serena/config/context_mode.py": "diff --git a/src/serena/config/context_mode.py b/src/serena/config/context_mode.py\nindex 44cd42f..f1f34fd 100644\n--- a/src/serena/config/context_mode.py\n+++ b/src/serena/config/context_mode.py\n@@ -4,7 +4,6 @@ Context and Mode configuration loader\n \n import os\n from dataclasses import dataclass, field\n-from enum import Enum\n from pathlib import Path\n from typing import TYPE_CHECKING, Self\n \n@@ -12,15 +11,14 @@ import yaml\n from sensai.util import logging\n from sensai.util.string import ToStringMixin\n \n-from serena.config.serena_config import ToolInclusionDefinition\n+from serena.config.serena_config import SerenaPaths, ToolInclusionDefinition\n from serena.constants import (\n     DEFAULT_CONTEXT,\n     DEFAULT_MODES,\n     INTERNAL_MODE_YAMLS_DIR,\n+    SERENA_FILE_ENCODING,\n     SERENAS_OWN_CONTEXT_YAMLS_DIR,\n     SERENAS_OWN_MODE_YAMLS_DIR,\n-    USER_CONTEXT_YAMLS_DIR,\n-    USER_MODE_YAMLS_DIR,\n )\n \n if TYPE_CHECKING:\n@@ -56,7 +54,7 @@ class SerenaAgentMode(ToolInclusionDefinition, ToStringMixin):\n     @classmethod\n     def from_yaml(cls, yaml_path: str | Path) -> Self:\n         \"\"\"Load a mode from a YAML file.\"\"\"\n-        with open(yaml_path, encoding=\"utf-8\") as f:\n+        with open(yaml_path, encoding=SERENA_FILE_ENCODING) as f:\n             data = yaml.safe_load(f)\n         name = data.pop(\"name\", Path(yaml_path).stem)\n         return cls(name=name, **data)\n@@ -65,14 +63,14 @@ class SerenaAgentMode(ToolInclusionDefinition, ToStringMixin):\n     def get_path(cls, name: str) -> str:\n         \"\"\"Get the path to the YAML file for a mode.\"\"\"\n         fname = f\"{name}.yml\"\n-        custom_mode_path = os.path.join(USER_MODE_YAMLS_DIR, fname)\n+        custom_mode_path = os.path.join(SerenaPaths().user_modes_dir, fname)\n         if os.path.exists(custom_mode_path):\n             return custom_mode_path\n \n         own_yaml_path = os.path.join(SERENAS_OWN_MODE_YAMLS_DIR, fname)\n         if not os.path.exists(own_yaml_path):\n             raise FileNotFoundError(\n-                f\"Mode {name} not found in {USER_MODE_YAMLS_DIR} or in {SERENAS_OWN_MODE_YAMLS_DIR}.\"\n+                f\"Mode {name} not found in {SerenaPaths().user_modes_dir} or in {SERENAS_OWN_MODE_YAMLS_DIR}.\"\n                 f\"Available modes:\\n{cls.list_registered_mode_names()}\"\n             )\n         return own_yaml_path\n@@ -102,7 +100,7 @@ class SerenaAgentMode(ToolInclusionDefinition, ToStringMixin):\n     @classmethod\n     def list_custom_mode_names(cls) -> list[str]:\n         \"\"\"Names of all custom modes defined by the user.\"\"\"\n-        return [f.stem for f in Path(USER_MODE_YAMLS_DIR).glob(\"*.yml\")]\n+        return [f.stem for f in Path(SerenaPaths().user_modes_dir).glob(\"*.yml\")]\n \n     @classmethod\n     def load_default_modes(cls) -> list[Self]:\n@@ -124,14 +122,29 @@ class SerenaAgentContext(ToolInclusionDefinition, ToStringMixin):\n     \"\"\"\n \n     name: str\n+    \"\"\"the name of the context\"\"\"\n+\n     prompt: str\n     \"\"\"\n     a Jinja2 template for the generation of the system prompt.\n     It is formatted by the agent (see SerenaAgent._format_prompt()).\n     \"\"\"\n+\n     description: str = \"\"\n+\n     tool_description_overrides: dict[str, str] = field(default_factory=dict)\n-    \"\"\"Maps tool names to custom descriptions, default descriptions are extracted from the tool docstrings.\"\"\"\n+    \"\"\"\n+    maps tool names to custom descriptions, default descriptions are extracted from the tool docstrings.\n+    \"\"\"\n+\n+    single_project: bool = False\n+    \"\"\"\n+    whether to assume that Serena shall only work on a single project in this context (provided that a project is given\n+    when Serena is started).\n+    If set to true and a project is provided at startup, the set of tools is limited to those required by the project's\n+    concrete configuration, and other tools are excluded completely, allowing the set of tools to be minimal.\n+    The `activate_project` tool will, therefore, be disabled in this case, as project switching is not allowed.\n+    \"\"\"\n \n     def _tostring_includes(self) -> list[str]:\n         return [\"name\"]\n@@ -139,7 +152,7 @@ class SerenaAgentContext(ToolInclusionDefinition, ToStringMixin):\n     @classmethod\n     def from_yaml(cls, yaml_path: str | Path) -> Self:\n         \"\"\"Load a context from a YAML file.\"\"\"\n-        with open(yaml_path, encoding=\"utf-8\") as f:\n+        with open(yaml_path, encoding=SERENA_FILE_ENCODING) as f:\n             data = yaml.safe_load(f)\n         name = data.pop(\"name\", Path(yaml_path).stem)\n         # Ensure backwards compatibility for tool_description_overrides\n@@ -151,14 +164,14 @@ class SerenaAgentContext(ToolInclusionDefinition, ToStringMixin):\n     def get_path(cls, name: str) -> str:\n         \"\"\"Get the path to the YAML file for a context.\"\"\"\n         fname = f\"{name}.yml\"\n-        custom_context_path = os.path.join(USER_CONTEXT_YAMLS_DIR, fname)\n+        custom_context_path = os.path.join(SerenaPaths().user_contexts_dir, fname)\n         if os.path.exists(custom_context_path):\n             return custom_context_path\n \n         own_yaml_path = os.path.join(SERENAS_OWN_CONTEXT_YAMLS_DIR, fname)\n         if not os.path.exists(own_yaml_path):\n             raise FileNotFoundError(\n-                f\"Context {name} not found in {USER_CONTEXT_YAMLS_DIR} or in {SERENAS_OWN_CONTEXT_YAMLS_DIR}.\"\n+                f\"Context {name} not found in {SerenaPaths().user_contexts_dir} or in {SERENAS_OWN_CONTEXT_YAMLS_DIR}.\"\n                 f\"Available contexts:\\n{cls.list_registered_context_names()}\"\n             )\n         return own_yaml_path\n@@ -166,6 +179,16 @@ class SerenaAgentContext(ToolInclusionDefinition, ToStringMixin):\n     @classmethod\n     def from_name(cls, name: str) -> Self:\n         \"\"\"Load a registered Serena context.\"\"\"\n+        legacy_name_mapping = {\n+            \"ide-assistant\": \"claude-code\",\n+        }\n+        if name in legacy_name_mapping:\n+            log.warning(\n+                f\"Context name '{name}' is deprecated and has been renamed to '{legacy_name_mapping[name]}'. \"\n+                f\"Please update your configuration; refer to the configuration guide for more details: \"\n+                \"https://oraios.github.io/serena/02-usage/050_configuration.html#contexts\"\n+            )\n+            name = legacy_name_mapping[name]\n         context_path = cls.get_path(name)\n         return cls.from_yaml(context_path)\n \n@@ -186,7 +209,7 @@ class SerenaAgentContext(ToolInclusionDefinition, ToStringMixin):\n     @classmethod\n     def list_custom_context_names(cls) -> list[str]:\n         \"\"\"Names of all custom contexts defined by the user.\"\"\"\n-        return [f.stem for f in Path(USER_CONTEXT_YAMLS_DIR).glob(\"*.yml\")]\n+        return [f.stem for f in Path(SerenaPaths().user_contexts_dir).glob(\"*.yml\")]\n \n     @classmethod\n     def load_default(cls) -> Self:\n@@ -198,35 +221,3 @@ class SerenaAgentContext(ToolInclusionDefinition, ToStringMixin):\n         print(f\"{self.name}:\\n {self.description}\")\n         if self.excluded_tools:\n             print(\" excluded tools:\\n  \" + \", \".join(sorted(self.excluded_tools)))\n-\n-\n-class RegisteredContext(Enum):\n-    \"\"\"A registered context.\"\"\"\n-\n-    IDE_ASSISTANT = \"ide-assistant\"\n-    \"\"\"For Serena running within an assistant that already has basic tools, like Claude Code, Cline, Cursor, etc.\"\"\"\n-    DESKTOP_APP = \"desktop-app\"\n-    \"\"\"For Serena running within Claude Desktop or a similar app which does not have built-in tools for code editing.\"\"\"\n-    AGENT = \"agent\"\n-    \"\"\"For Serena running as a standalone agent, e.g. through agno.\"\"\"\n-\n-    def load(self) -> SerenaAgentContext:\n-        \"\"\"Load the context.\"\"\"\n-        return SerenaAgentContext.from_name(self.value)\n-\n-\n-class RegisteredMode(Enum):\n-    \"\"\"A registered mode.\"\"\"\n-\n-    INTERACTIVE = \"interactive\"\n-    \"\"\"Interactive mode, for multi-turn interactions.\"\"\"\n-    EDITING = \"editing\"\n-    \"\"\"Editing tools are activated.\"\"\"\n-    PLANNING = \"planning\"\n-    \"\"\"Editing tools are deactivated.\"\"\"\n-    ONE_SHOT = \"one-shot\"\n-    \"\"\"Non-interactive mode, where the goal is to finish a task autonomously.\"\"\"\n-\n-    def load(self) -> SerenaAgentMode:\n-        \"\"\"Load the mode.\"\"\"\n-        return SerenaAgentMode.from_name(self.value)\n",
    "src/serena/config/serena_config.py": "diff --git a/src/serena/config/serena_config.py b/src/serena/config/serena_config.py\nindex 2eac751..aa8ec35 100644\n--- a/src/serena/config/serena_config.py\n+++ b/src/serena/config/serena_config.py\n@@ -2,12 +2,14 @@\n The Serena Model Context Protocol (MCP) Server\n \"\"\"\n \n+import dataclasses\n import os\n import shutil\n from collections.abc import Iterable\n from copy import deepcopy\n from dataclasses import dataclass, field\n from datetime import datetime\n+from enum import Enum\n from functools import cached_property\n from pathlib import Path\n from typing import TYPE_CHECKING, Any, Optional, Self, TypeVar\n@@ -19,19 +21,20 @@ from sensai.util.logging import LogTime, datetime_tag\n from sensai.util.string import ToStringMixin\n \n from serena.constants import (\n-    DEFAULT_ENCODING,\n+    DEFAULT_SOURCE_FILE_ENCODING,\n     PROJECT_TEMPLATE_FILE,\n     REPO_ROOT,\n     SERENA_CONFIG_TEMPLATE_FILE,\n-    SERENA_MANAGED_DIR_IN_HOME,\n+    SERENA_FILE_ENCODING,\n     SERENA_MANAGED_DIR_NAME,\n )\n-from serena.util.general import load_yaml, save_yaml\n+from serena.util.general import get_dataclass_default, load_yaml, save_yaml\n from serena.util.inspection import determine_programming_language_composition\n from solidlsp.ls_config import Language\n \n from ..analytics import RegisteredTokenCountEstimator\n from ..util.class_decorators import singleton\n+from ..util.cli_util import ask_yes_no\n \n if TYPE_CHECKING:\n     from ..project import Project\n@@ -39,6 +42,8 @@ if TYPE_CHECKING:\n log = logging.getLogger(__name__)\n T = TypeVar(\"T\")\n DEFAULT_TOOL_TIMEOUT: float = 240\n+DictType = dict | CommentedMap\n+TDict = TypeVar(\"TDict\", bound=DictType)\n \n \n @singleton\n@@ -48,87 +53,44 @@ class SerenaPaths:\n     \"\"\"\n \n     def __init__(self) -> None:\n-        self.user_config_dir: str = SERENA_MANAGED_DIR_IN_HOME\n+        home_dir = os.getenv(\"SERENA_HOME\")\n+        if home_dir is None or home_dir.strip() == \"\":\n+            home_dir = str(Path.home() / SERENA_MANAGED_DIR_NAME)\n+        else:\n+            home_dir = home_dir.strip()\n+        self.serena_user_home_dir: str = home_dir\n         \"\"\"\n-        the path to the user's Serena configuration directory, which is typically ~/.serena\n+        the path to the Serena home directory, where the user's configuration/data is stored.\n+        This is ~/.serena by default, but it can be overridden via the SERENA_HOME environment variable.\n         \"\"\"\n-\n-    def get_next_log_file_path(self, prefix: str) -> str:\n+        self.user_prompt_templates_dir: str = os.path.join(self.serena_user_home_dir, \"prompt_templates\")\n         \"\"\"\n-        :param prefix: the filename prefix indicating the type of the log file\n-        :return: the full path to the log file to use\n+        directory containing prompt templates defined by the user.\n+        Prompts defined by the user take precedence over Serena's built-in prompt templates.\n         \"\"\"\n-        log_dir = os.path.join(self.user_config_dir, \"logs\", datetime.now().strftime(\"%Y-%m-%d\"))\n-        os.makedirs(log_dir, exist_ok=True)\n-        return os.path.join(log_dir, prefix + \"_\" + datetime_tag() + \".txt\")\n-\n-    # TODO: Paths from constants.py should be moved here\n-\n-\n-class ToolSet:\n-    def __init__(self, tool_names: set[str]) -> None:\n-        self._tool_names = tool_names\n-\n-    @classmethod\n-    def default(cls) -> \"ToolSet\":\n+        self.user_contexts_dir: str = os.path.join(self.serena_user_home_dir, \"contexts\")\n         \"\"\"\n-        :return: the default tool set, which contains all tools that are enabled by default\n+        directory containing contexts defined by the user. \n+        If a name of a context matches a name of a context in SERENAS_OWN_CONTEXT_YAMLS_DIR, \n+        the user context will override the default context definition.\n         \"\"\"\n-        from serena.tools import ToolRegistry\n-\n-        return cls(set(ToolRegistry().get_tool_names_default_enabled()))\n-\n-    def apply(self, *tool_inclusion_definitions: \"ToolInclusionDefinition\") -> \"ToolSet\":\n+        self.user_modes_dir: str = os.path.join(self.serena_user_home_dir, \"modes\")\n         \"\"\"\n-        :param tool_inclusion_definitions: the definitions to apply\n-        :return: a new tool set with the definitions applied\n+        directory containing modes defined by the user.\n+        If a name of a mode matches a name of a mode in SERENAS_OWN_MODES_YAML_DIR,\n+        the user mode will override the default mode definition.\n         \"\"\"\n-        from serena.tools import ToolRegistry\n-\n-        registry = ToolRegistry()\n-        tool_names = set(self._tool_names)\n-        for definition in tool_inclusion_definitions:\n-            included_tools = []\n-            excluded_tools = []\n-            for included_tool in definition.included_optional_tools:\n-                if not registry.is_valid_tool_name(included_tool):\n-                    raise ValueError(f\"Invalid tool name '{included_tool}' provided for inclusion\")\n-                if included_tool not in tool_names:\n-                    tool_names.add(included_tool)\n-                    included_tools.append(included_tool)\n-            for excluded_tool in definition.excluded_tools:\n-                if not registry.is_valid_tool_name(excluded_tool):\n-                    raise ValueError(f\"Invalid tool name '{excluded_tool}' provided for exclusion\")\n-                if excluded_tool in self._tool_names:\n-                    tool_names.remove(excluded_tool)\n-                    excluded_tools.append(excluded_tool)\n-            if included_tools:\n-                log.info(f\"{definition} included {len(included_tools)} tools: {', '.join(included_tools)}\")\n-            if excluded_tools:\n-                log.info(f\"{definition} excluded {len(excluded_tools)} tools: {', '.join(excluded_tools)}\")\n-        return ToolSet(tool_names)\n \n-    def without_editing_tools(self) -> \"ToolSet\":\n-        \"\"\"\n-        :return: a new tool set that excludes all tools that can edit\n-        \"\"\"\n-        from serena.tools import ToolRegistry\n-\n-        registry = ToolRegistry()\n-        tool_names = set(self._tool_names)\n-        for tool_name in self._tool_names:\n-            if registry.get_tool_class_by_name(tool_name).can_edit():\n-                tool_names.remove(tool_name)\n-        return ToolSet(tool_names)\n-\n-    def get_tool_names(self) -> set[str]:\n+    def get_next_log_file_path(self, prefix: str) -> str:\n         \"\"\"\n-        Returns the names of the tools that are currently included in the tool set.\n+        :param prefix: the filename prefix indicating the type of the log file\n+        :return: the full path to the log file to use\n         \"\"\"\n-        return self._tool_names\n+        log_dir = os.path.join(self.serena_user_home_dir, \"logs\", datetime.now().strftime(\"%Y-%m-%d\"))\n+        os.makedirs(log_dir, exist_ok=True)\n+        return os.path.join(log_dir, prefix + \"_\" + datetime_tag() + \".txt\")\n \n-    def includes_name(self, tool_name: str) -> bool:\n-        return tool_name in self._tool_names\n+    # TODO: Paths from constants.py should be moved here\n \n \n @dataclass\n@@ -145,28 +107,35 @@ def get_serena_managed_in_project_dir(project_root: str | Path) -> str:\n     return os.path.join(project_root, SERENA_MANAGED_DIR_NAME)\n \n \n-def is_running_in_docker() -> bool:\n-    \"\"\"Check if we're running inside a Docker container.\"\"\"\n-    # Check for Docker-specific files\n-    if os.path.exists(\"/.dockerenv\"):\n-        return True\n-    # Check cgroup for docker references\n-    try:\n-        with open(\"/proc/self/cgroup\") as f:\n-            return \"docker\" in f.read()\n-    except FileNotFoundError:\n-        return False\n+class LanguageBackend(Enum):\n+    LSP = \"LSP\"\n+    \"\"\"\n+    Use the language server protocol (LSP), spawning freely available language servers\n+    via the SolidLSP library that is part of Serena\n+    \"\"\"\n+    JETBRAINS = \"JetBrains\"\n+    \"\"\"\n+    Use the Serena plugin in your JetBrains IDE.\n+    (requires the plugin to be installed and the project being worked on to be open in your IDE)\n+    \"\"\"\n+\n+    @staticmethod\n+    def from_str(backend_str: str) -> \"LanguageBackend\":\n+        for backend in LanguageBackend:\n+            if backend.value.lower() == backend_str.lower():\n+                return backend\n+        raise ValueError(f\"Unknown language backend '{backend_str}': valid values are {[b.value for b in LanguageBackend]}\")\n \n \n @dataclass(kw_only=True)\n class ProjectConfig(ToolInclusionDefinition, ToStringMixin):\n     project_name: str\n-    language: Language\n+    languages: list[Language]\n     ignored_paths: list[str] = field(default_factory=list)\n     read_only: bool = False\n     ignore_all_files_in_gitignore: bool = True\n     initial_prompt: str = \"\"\n-    encoding: str = DEFAULT_ENCODING\n+    encoding: str = DEFAULT_SOURCE_FILE_ENCODING\n \n     SERENA_DEFAULT_PROJECT_FILE = \"project.yml\"\n \n@@ -175,7 +144,12 @@ class ProjectConfig(ToolInclusionDefinition, ToStringMixin):\n \n     @classmethod\n     def autogenerate(\n-        cls, project_root: str | Path, project_name: str | None = None, project_language: Language | None = None, save_to_disk: bool = True\n+        cls,\n+        project_root: str | Path,\n+        project_name: str | None = None,\n+        languages: list[Language] | None = None,\n+        save_to_disk: bool = True,\n+        interactive: bool = False,\n     ) -> Self:\n         \"\"\"\n         Autogenerate a project configuration for a given project root.\n@@ -183,70 +157,150 @@ class ProjectConfig(ToolInclusionDefinition, ToStringMixin):\n         :param project_root: the path to the project root\n         :param project_name: the name of the project; if None, the name of the project will be the name of the directory\n             containing the project\n-        :param project_language: the programming language of the project; if None, it will be determined automatically\n+        :param languages: the languages of the project; if None, they will be determined automatically\n         :param save_to_disk: whether to save the project configuration to disk\n+        :param interactive: whether to run in interactive CLI mode, asking the user for input where appropriate\n         :return: the project configuration\n         \"\"\"\n         project_root = Path(project_root).resolve()\n         if not project_root.exists():\n             raise FileNotFoundError(f\"Project root not found: {project_root}\")\n         with LogTime(\"Project configuration auto-generation\", logger=log):\n+            log.info(\"Project root: %s\", project_root)\n             project_name = project_name or project_root.name\n-            if project_language is None:\n+            if languages is None:\n+                # determine languages automatically\n+                log.info(\"Determining programming languages used in the project\")\n                 language_composition = determine_programming_language_composition(str(project_root))\n+                log.info(\"Language composition: %s\", language_composition)\n                 if len(language_composition) == 0:\n+                    language_values = \", \".join([lang.value for lang in Language])\n                     raise ValueError(\n                         f\"No source files found in {project_root}\\n\\n\"\n-                        f\"To use Serena with this project, you need to either:\\n\"\n-                        f\"1. Add source files in one of the supported languages (Python, JavaScript/TypeScript, Java, C#, Rust, Go, Ruby, C++, PHP, Swift, Elixir, Terraform, Bash)\\n\"\n-                        f\"2. Create a project configuration file manually at:\\n\"\n-                        f\"   {os.path.join(project_root, cls.rel_path_to_project_yml())}\\n\\n\"\n-                        f\"Example project.yml:\\n\"\n-                        f\"  project_name: {project_name}\\n\"\n-                        f\"  language: python  # or typescript, java, csharp, rust, go, ruby, cpp, php, swift, elixir, terraform, bash\\n\"\n+                        f\"To use Serena with this project, you need to either\\n\"\n+                        f\"  1. specify a programming language by adding parameters --language <language>\\n\"\n+                        f\"     when creating the project via the Serena CLI command OR\\n\"\n+                        f\"  2. add source files in one of the supported languages first.\\n\\n\"\n+                        f\"Supported languages are: {language_values}\\n\"\n+                        f\"Read the documentation for more information.\"\n+                    )\n+                # sort languages by number of files found\n+                languages_and_percentages = sorted(\n+                    language_composition.items(), key=lambda item: (item[1], item[0].get_priority()), reverse=True\n+                )\n+                # find the language with the highest percentage and enable it\n+                top_language_pair = languages_and_percentages[0]\n+                other_language_pairs = languages_and_percentages[1:]\n+                languages_to_use: list[str] = [top_language_pair[0].value]\n+                # if in interactive mode, ask the user which other languages to enable\n+                if len(other_language_pairs) > 0 and interactive:\n+                    print(\n+                        \"Detected and enabled main language '%s' (%.2f%% of source files).\"\n+                        % (top_language_pair[0].value, top_language_pair[1])\n                     )\n-                # find the language with the highest percentage\n-                dominant_language = max(language_composition.keys(), key=lambda lang: language_composition[lang])\n+                    print(f\"Additionally detected {len(other_language_pairs)} other language(s).\\n\")\n+                    print(\"Note: Enable only languages you need symbolic retrieval/editing capabilities for.\")\n+                    print(\"      Additional language servers use resources and some languages may require additional\")\n+                    print(\"      system-level installations/configuration (see Serena documentation).\")\n+                    print(\"\\nWhich additional languages do you want to enable?\")\n+                    for lang, perc in other_language_pairs:\n+                        enable = ask_yes_no(\"Enable %s (%.2f%% of source files)?\" % (lang.value, perc), default=False)\n+                        if enable:\n+                            languages_to_use.append(lang.value)\n+                    print()\n+                log.info(\"Using languages: %s\", languages_to_use)\n             else:\n-                dominant_language = project_language.value\n-            config_with_comments = load_yaml(PROJECT_TEMPLATE_FILE, preserve_comments=True)\n+                languages_to_use = [lang.value for lang in languages]\n+            config_with_comments = cls.load_commented_map(PROJECT_TEMPLATE_FILE)\n             config_with_comments[\"project_name\"] = project_name\n-            config_with_comments[\"language\"] = dominant_language\n+            config_with_comments[\"languages\"] = languages_to_use\n             if save_to_disk:\n-                save_yaml(str(project_root / cls.rel_path_to_project_yml()), config_with_comments, preserve_comments=True)\n+                project_yml_path = cls.path_to_project_yml(project_root)\n+                log.info(\"Saving project configuration to %s\", project_yml_path)\n+                save_yaml(project_yml_path, config_with_comments, preserve_comments=True)\n             return cls._from_dict(config_with_comments)\n \n+    @classmethod\n+    def path_to_project_yml(cls, project_root: str | Path) -> str:\n+        return os.path.join(project_root, cls.rel_path_to_project_yml())\n+\n     @classmethod\n     def rel_path_to_project_yml(cls) -> str:\n         return os.path.join(SERENA_MANAGED_DIR_NAME, cls.SERENA_DEFAULT_PROJECT_FILE)\n \n     @classmethod\n-    def _from_dict(cls, data: dict[str, Any]) -> Self:\n+    def _apply_defaults_to_dict(cls, data: TDict) -> TDict:\n+        # apply defaults for new fields\n+        data[\"languages\"] = data.get(\"languages\", [])\n+        data[\"ignored_paths\"] = data.get(\"ignored_paths\", [])\n+        data[\"excluded_tools\"] = data.get(\"excluded_tools\", [])\n+        data[\"included_optional_tools\"] = data.get(\"included_optional_tools\", [])\n+        data[\"read_only\"] = data.get(\"read_only\", False)\n+        data[\"ignore_all_files_in_gitignore\"] = data.get(\"ignore_all_files_in_gitignore\", True)\n+        data[\"initial_prompt\"] = data.get(\"initial_prompt\", \"\")\n+        data[\"encoding\"] = data.get(\"encoding\", DEFAULT_SOURCE_FILE_ENCODING)\n+\n+        # backward compatibility: handle single \"language\" field\n+        if len(data[\"languages\"]) == 0 and \"language\" in data:\n+            data[\"languages\"] = [data[\"language\"]]\n+        if \"language\" in data:\n+            del data[\"language\"]\n+\n+        return data\n+\n+    @classmethod\n+    def load_commented_map(cls, yml_path: str) -> CommentedMap:\n         \"\"\"\n-        Create a ProjectConfig instance from a configuration dictionary\n+        Load the project configuration as a CommentedMap, preserving comments and ensuring\n+        completeness of the configuration by applying default values for missing fields\n+        and backward compatibility adjustments.\n+\n+        :param yml_path: the path to the project.yml file\n+        :return: a CommentedMap representing a full project configuration\n         \"\"\"\n-        language_str = data[\"language\"].lower()\n-        project_name = data[\"project_name\"]\n-        # backwards compatibility\n-        if language_str == \"javascript\":\n-            log.warning(f\"Found deprecated project language `javascript` in project {project_name}, please change to `typescript`\")\n-            language_str = \"typescript\"\n-        try:\n-            language = Language(language_str)\n-        except ValueError as e:\n-            raise ValueError(f\"Invalid language: {data['language']}.\\nValid languages are: {[l.value for l in Language]}\") from e\n+        data = load_yaml(yml_path, preserve_comments=True)\n+        return cls._apply_defaults_to_dict(data)\n+\n+    @classmethod\n+    def _from_dict(cls, data: dict[str, Any]) -> Self:\n+        \"\"\"\n+        Create a ProjectConfig instance from a (full) configuration dictionary\n+        \"\"\"\n+        lang_name_mapping = {\"javascript\": \"typescript\"}\n+        languages: list[Language] = []\n+        for language_str in data[\"languages\"]:\n+            orig_language_str = language_str\n+            try:\n+                language_str = language_str.lower()\n+                if language_str in lang_name_mapping:\n+                    language_str = lang_name_mapping[language_str]\n+                language = Language(language_str)\n+                languages.append(language)\n+            except ValueError as e:\n+                raise ValueError(\n+                    f\"Invalid language: {orig_language_str}.\\nValid language_strings are: {[l.value for l in Language]}\"\n+                ) from e\n+\n         return cls(\n-            project_name=project_name,\n-            language=language,\n-            ignored_paths=data.get(\"ignored_paths\", []),\n-            excluded_tools=data.get(\"excluded_tools\", []),\n-            included_optional_tools=data.get(\"included_optional_tools\", []),\n-            read_only=data.get(\"read_only\", False),\n-            ignore_all_files_in_gitignore=data.get(\"ignore_all_files_in_gitignore\", True),\n-            initial_prompt=data.get(\"initial_prompt\", \"\"),\n-            encoding=data.get(\"encoding\", DEFAULT_ENCODING),\n+            project_name=data[\"project_name\"],\n+            languages=languages,\n+            ignored_paths=data[\"ignored_paths\"],\n+            excluded_tools=data[\"excluded_tools\"],\n+            included_optional_tools=data[\"included_optional_tools\"],\n+            read_only=data[\"read_only\"],\n+            ignore_all_files_in_gitignore=data[\"ignore_all_files_in_gitignore\"],\n+            initial_prompt=data[\"initial_prompt\"],\n+            encoding=data[\"encoding\"],\n         )\n \n+    def to_yaml_dict(self) -> dict:\n+        \"\"\"\n+        :return: a yaml-serializable dictionary representation of this configuration\n+        \"\"\"\n+        d = dataclasses.asdict(self)\n+        d[\"languages\"] = [lang.value for lang in self.languages]\n+        return d\n+\n     @classmethod\n     def load(cls, project_root: Path | str, autogenerate: bool = False) -> Self:\n         \"\"\"\n@@ -259,8 +313,7 @@ class ProjectConfig(ToolInclusionDefinition, ToStringMixin):\n                 return cls.autogenerate(project_root)\n             else:\n                 raise FileNotFoundError(f\"Project configuration file not found: {yaml_path}\")\n-        with open(yaml_path, encoding=\"utf-8\") as f:\n-            yaml_data = yaml.safe_load(f)\n+        yaml_data = cls.load_commented_map(str(yaml_path))\n         if \"project_name\" not in yaml_data:\n             yaml_data[\"project_name\"] = project_root.name\n         return cls._from_dict(yaml_data)\n@@ -328,6 +381,7 @@ class SerenaConfig(ToolInclusionDefinition, ToStringMixin):\n     trace_lsp_communication: bool = False\n     web_dashboard: bool = True\n     web_dashboard_open_on_launch: bool = True\n+    web_dashboard_listen_address: str = \"127.0.0.1\"\n     tool_timeout: float = DEFAULT_TOOL_TIMEOUT\n     loaded_commented_yaml: CommentedMap | None = None\n     config_file_path: str | None = None\n@@ -335,14 +389,13 @@ class SerenaConfig(ToolInclusionDefinition, ToStringMixin):\n     the path to the configuration file to which updates of the configuration shall be saved;\n     if None, the configuration is not saved to disk\n     \"\"\"\n-    jetbrains: bool = False\n-    \"\"\"\n-    whether to apply JetBrains mode\n+\n+    language_backend: LanguageBackend = LanguageBackend.LSP\n     \"\"\"\n-    record_tool_usage_stats: bool = False\n-    \"\"\"Whether to record tool usage statistics, they will be shown in the web dashboard if recording is active. \n+    the language backend to use for code understanding features\n     \"\"\"\n-    token_count_estimator: str = RegisteredTokenCountEstimator.TIKTOKEN_GPT4O.name\n+\n+    token_count_estimator: str = RegisteredTokenCountEstimator.CHAR_COUNT.name\n     \"\"\"Only relevant if `record_tool_usage` is True; the name of the token count estimator to use for tool usage statistics.\n     See the `RegisteredTokenCountEstimator` enum for available options.\n     \n@@ -355,15 +408,16 @@ class SerenaConfig(ToolInclusionDefinition, ToStringMixin):\n     Even though the value of the max_answer_chars can be changed when calling the tool, it may make sense to adjust this default \n     through the global configuration.\n     \"\"\"\n+    ls_specific_settings: dict = field(default_factory=dict)\n+    \"\"\"Advanced configuration option allowing to configure language server implementation specific options, see SolidLSPSettings for more info.\"\"\"\n \n     CONFIG_FILE = \"serena_config.yml\"\n-    CONFIG_FILE_DOCKER = \"serena_config.docker.yml\"  # Docker-specific config file; auto-generated if missing, mounted via docker-compose for user customization\n \n     def _tostring_includes(self) -> list[str]:\n         return [\"config_file_path\"]\n \n     @classmethod\n-    def generate_config_file(cls, config_file_path: str) -> None:\n+    def _generate_config_file(cls, config_file_path: str) -> None:\n         \"\"\"\n         Generates a Serena configuration file at the specified path from the template file.\n \n@@ -378,20 +432,17 @@ class SerenaConfig(ToolInclusionDefinition, ToStringMixin):\n         \"\"\"\n         :return: the location where the Serena configuration file is stored/should be stored\n         \"\"\"\n-        if is_running_in_docker():\n-            return os.path.join(REPO_ROOT, cls.CONFIG_FILE_DOCKER)\n-        else:\n-            config_path = os.path.join(SERENA_MANAGED_DIR_IN_HOME, cls.CONFIG_FILE)\n+        config_path = os.path.join(SerenaPaths().serena_user_home_dir, cls.CONFIG_FILE)\n \n-            # if the config file does not exist, check if we can migrate it from the old location\n-            if not os.path.exists(config_path):\n-                old_config_path = os.path.join(REPO_ROOT, cls.CONFIG_FILE)\n-                if os.path.exists(old_config_path):\n-                    log.info(f\"Moving Serena configuration file from {old_config_path} to {config_path}\")\n-                    os.makedirs(os.path.dirname(config_path), exist_ok=True)\n-                    shutil.move(old_config_path, config_path)\n+        # if the config file does not exist, check if we can migrate it from the old location\n+        if not os.path.exists(config_path):\n+            old_config_path = os.path.join(REPO_ROOT, cls.CONFIG_FILE)\n+            if os.path.exists(old_config_path):\n+                log.info(f\"Moving Serena configuration file from {old_config_path} to {config_path}\")\n+                os.makedirs(os.path.dirname(config_path), exist_ok=True)\n+                shutil.move(old_config_path, config_path)\n \n-            return config_path\n+        return config_path\n \n     @classmethod\n     def from_config_file(cls, generate_if_missing: bool = True) -> \"SerenaConfig\":\n@@ -405,7 +456,7 @@ class SerenaConfig(ToolInclusionDefinition, ToStringMixin):\n             if not generate_if_missing:\n                 raise FileNotFoundError(f\"Serena configuration file not found: {config_file_path}\")\n             log.info(f\"Serena configuration file not found at {config_file_path}, autogenerating...\")\n-            cls.generate_config_file(config_file_path)\n+            cls._generate_config_file(config_file_path)\n \n         # load the configuration\n         log.info(f\"Loading Serena configuration from {config_file_path}\")\n@@ -423,7 +474,7 @@ class SerenaConfig(ToolInclusionDefinition, ToStringMixin):\n \n         # load list of known projects\n         instance.projects = []\n-        num_project_migrations = 0\n+        num_migrations = 0\n         for path in loaded_commented_yaml[\"projects\"]:\n             path = Path(path).resolve()\n             if not path.exists() or (path.is_dir() and not (path / ProjectConfig.rel_path_to_project_yml()).exists()):\n@@ -433,7 +484,7 @@ class SerenaConfig(ToolInclusionDefinition, ToStringMixin):\n                 path = cls._migrate_out_of_project_config_file(path)\n                 if path is None:\n                     continue\n-                num_project_migrations += 1\n+                num_migrations += 1\n             project_config = ProjectConfig.load(path)\n             project = RegisteredProject(\n                 project_root=str(path),\n@@ -441,30 +492,42 @@ class SerenaConfig(ToolInclusionDefinition, ToStringMixin):\n             )\n             instance.projects.append(project)\n \n-        # set other configuration parameters\n-        if is_running_in_docker():\n-            instance.gui_log_window_enabled = False  # not supported in Docker\n+        def get_value_or_default(key: str, field_name: str | None = None) -> Any:\n+            if field_name is None:\n+                field_name = key\n+            return loaded_commented_yaml.get(key, get_dataclass_default(SerenaConfig, field_name))\n+\n+        # determine language backend\n+        language_backend = get_dataclass_default(SerenaConfig, \"language_backend\")\n+        if \"language_backend\" in loaded_commented_yaml:\n+            backend_str = loaded_commented_yaml[\"language_backend\"]\n+            language_backend = LanguageBackend.from_str(backend_str)\n         else:\n-            instance.gui_log_window_enabled = loaded_commented_yaml.get(\"gui_log_window\", False)\n+            # backward compatibility (migrate Boolean field \"jetbrains\")\n+            if \"jetbrains\" in loaded_commented_yaml:\n+                num_migrations += 1\n+                if loaded_commented_yaml[\"jetbrains\"]:\n+                    language_backend = LanguageBackend.JETBRAINS\n+                del loaded_commented_yaml[\"jetbrains\"]\n+        instance.language_backend = language_backend\n+\n+        # set other configuration parameters (primitive types)\n+        instance.gui_log_window_enabled = get_value_or_default(\"gui_log_window\", \"gui_log_window_enabled\")\n+        instance.web_dashboard_listen_address = get_value_or_default(\"web_dashboard_listen_address\")\n         instance.log_level = loaded_commented_yaml.get(\"log_level\", loaded_commented_yaml.get(\"gui_log_level\", logging.INFO))\n-        instance.web_dashboard = loaded_commented_yaml.get(\"web_dashboard\", True)\n-        instance.web_dashboard_open_on_launch = loaded_commented_yaml.get(\"web_dashboard_open_on_launch\", True)\n-        instance.tool_timeout = loaded_commented_yaml.get(\"tool_timeout\", DEFAULT_TOOL_TIMEOUT)\n-        instance.trace_lsp_communication = loaded_commented_yaml.get(\"trace_lsp_communication\", False)\n-        instance.excluded_tools = loaded_commented_yaml.get(\"excluded_tools\", [])\n-        instance.included_optional_tools = loaded_commented_yaml.get(\"included_optional_tools\", [])\n-        instance.jetbrains = loaded_commented_yaml.get(\"jetbrains\", False)\n-        instance.record_tool_usage_stats = loaded_commented_yaml.get(\"record_tool_usage_stats\", False)\n-        instance.token_count_estimator = loaded_commented_yaml.get(\n-            \"token_count_estimator\", RegisteredTokenCountEstimator.TIKTOKEN_GPT4O.name\n-        )\n-        instance.default_max_tool_answer_chars = loaded_commented_yaml.get(\"default_max_tool_answer_chars\", 150_000)\n+        instance.web_dashboard = get_value_or_default(\"web_dashboard\")\n+        instance.web_dashboard_open_on_launch = get_value_or_default(\"web_dashboard_open_on_launch\")\n+        instance.tool_timeout = get_value_or_default(\"tool_timeout\")\n+        instance.trace_lsp_communication = get_value_or_default(\"trace_lsp_communication\")\n+        instance.excluded_tools = get_value_or_default(\"excluded_tools\")\n+        instance.included_optional_tools = get_value_or_default(\"included_optional_tools\")\n+        instance.token_count_estimator = get_value_or_default(\"token_count_estimator\")\n+        instance.default_max_tool_answer_chars = get_value_or_default(\"default_max_tool_answer_chars\")\n+        instance.ls_specific_settings = get_value_or_default(\"ls_specific_settings\")\n \n         # re-save the configuration file if any migrations were performed\n-        if num_project_migrations > 0:\n-            log.info(\n-                f\"Migrated {num_project_migrations} project configurations from legacy format to in-project configuration; re-saving configuration\"\n-            )\n+        if num_migrations > 0:\n+            log.info(\"Legacy configuration was migrated; re-saving configuration file\")\n             instance.save()\n \n         return instance\n@@ -480,11 +543,11 @@ class SerenaConfig(ToolInclusionDefinition, ToStringMixin):\n         \"\"\"\n         log.info(f\"Found legacy project configuration file {path}, migrating to in-project configuration.\")\n         try:\n-            with open(path, encoding=\"utf-8\") as f:\n+            with open(path, encoding=SERENA_FILE_ENCODING) as f:\n                 project_config_data = yaml.safe_load(f)\n             if \"project_name\" not in project_config_data:\n                 project_name = path.stem\n-                with open(path, \"a\", encoding=\"utf-8\") as f:\n+                with open(path, \"a\", encoding=SERENA_FILE_ENCODING) as f:\n                     f.write(f\"\\nproject_name: {project_name}\")\n             project_root = project_config_data[\"project_root\"]\n             shutil.move(str(path), str(Path(project_root) / ProjectConfig.rel_path_to_project_yml()))\n@@ -567,9 +630,15 @@ class SerenaConfig(ToolInclusionDefinition, ToStringMixin):\n         \"\"\"\n         if self.config_file_path is None:\n             return\n+\n         assert self.loaded_commented_yaml is not None, \"Cannot save configuration without loaded YAML\"\n+\n         loaded_original_yaml = deepcopy(self.loaded_commented_yaml)\n-        # projects are unique absolute paths\n-        # we also canonicalize them before saving\n+\n+        # convert project objects into list of paths\n         loaded_original_yaml[\"projects\"] = sorted({str(project.project_root) for project in self.projects})\n+\n+        # convert language backend to string\n+        loaded_original_yaml[\"language_backend\"] = self.language_backend.value\n+\n         save_yaml(self.config_file_path, loaded_original_yaml, preserve_comments=True)\n",
    "src/serena/project.py": "diff --git a/src/serena/project.py b/src/serena/project.py\nindex d2da0d0..968ad54 100644\n--- a/src/serena/project.py\n+++ b/src/serena/project.py\n@@ -1,26 +1,66 @@\n+import json\n import logging\n import os\n from pathlib import Path\n+from typing import Any\n \n import pathspec\n+from sensai.util.string import ToStringMixin\n \n-from serena.config.serena_config import DEFAULT_TOOL_TIMEOUT, ProjectConfig\n-from serena.constants import SERENA_MANAGED_DIR_IN_HOME, SERENA_MANAGED_DIR_NAME\n+from serena.config.serena_config import DEFAULT_TOOL_TIMEOUT, ProjectConfig, get_serena_managed_in_project_dir\n+from serena.constants import SERENA_FILE_ENCODING, SERENA_MANAGED_DIR_NAME\n+from serena.ls_manager import LanguageServerFactory, LanguageServerManager\n from serena.text_utils import MatchedConsecutiveLines, search_files\n from serena.util.file_system import GitignoreParser, match_path\n+from serena.util.general import save_yaml\n from solidlsp import SolidLanguageServer\n-from solidlsp.ls_config import Language, LanguageServerConfig\n-from solidlsp.ls_logger import LanguageServerLogger\n-from solidlsp.settings import SolidLSPSettings\n+from solidlsp.ls_config import Language\n+from solidlsp.ls_utils import FileUtils\n \n log = logging.getLogger(__name__)\n \n \n-class Project:\n+class MemoriesManager:\n+    def __init__(self, project_root: str):\n+        self._memory_dir = Path(get_serena_managed_in_project_dir(project_root)) / \"memories\"\n+        self._memory_dir.mkdir(parents=True, exist_ok=True)\n+        self._encoding = SERENA_FILE_ENCODING\n+\n+    def get_memory_file_path(self, name: str) -> Path:\n+        # strip all .md from the name. Models tend to get confused, sometimes passing the .md extension and sometimes not.\n+        name = name.replace(\".md\", \"\")\n+        filename = f\"{name}.md\"\n+        return self._memory_dir / filename\n+\n+    def load_memory(self, name: str) -> str:\n+        memory_file_path = self.get_memory_file_path(name)\n+        if not memory_file_path.exists():\n+            return f\"Memory file {name} not found, consider creating it with the `write_memory` tool if you need it.\"\n+        with open(memory_file_path, encoding=self._encoding) as f:\n+            return f.read()\n+\n+    def save_memory(self, name: str, content: str) -> str:\n+        memory_file_path = self.get_memory_file_path(name)\n+        with open(memory_file_path, \"w\", encoding=self._encoding) as f:\n+            f.write(content)\n+        return f\"Memory {name} written.\"\n+\n+    def list_memories(self) -> list[str]:\n+        return [f.name.replace(\".md\", \"\") for f in self._memory_dir.iterdir() if f.is_file()]\n+\n+    def delete_memory(self, name: str) -> str:\n+        memory_file_path = self.get_memory_file_path(name)\n+        memory_file_path.unlink()\n+        return f\"Memory {name} deleted.\"\n+\n+\n+class Project(ToStringMixin):\n     def __init__(self, project_root: str, project_config: ProjectConfig, is_newly_created: bool = False):\n         self.project_root = project_root\n         self.project_config = project_config\n-        self.is_newly_created = is_newly_created\n+        self.memories_manager = MemoriesManager(project_root)\n+        self.language_server_manager: LanguageServerManager | None = None\n+        self._is_newly_created = is_newly_created\n \n         # create .gitignore file in the project's Serena data folder if not yet present\n         serena_data_gitignore_path = os.path.join(self.path_to_serena_data_folder(), \".gitignore\")\n@@ -31,7 +71,7 @@ class Project:\n                 f.write(f\"/{SolidLanguageServer.CACHE_FOLDER_NAME}\\n\")\n \n         # gather ignored paths from the project configuration and gitignore files\n-        ignored_patterns = project_config.ignored_paths\n+        ignored_patterns = list(project_config.ignored_paths)\n         if len(ignored_patterns) > 0:\n             log.info(f\"Using {len(ignored_patterns)} ignored paths from the explicit project configuration.\")\n             log.debug(f\"Ignored paths: {ignored_patterns}\")\n@@ -52,14 +92,16 @@ class Project:\n         log.debug(f\"Processing {len(processed_patterns)} ignored paths\")\n         self._ignore_spec = pathspec.PathSpec.from_lines(pathspec.patterns.GitWildMatchPattern, processed_patterns)\n \n+    def _tostring_includes(self) -> list[str]:\n+        return []\n+\n+    def _tostring_additional_entries(self) -> dict[str, Any]:\n+        return {\"root\": self.project_root, \"name\": self.project_name}\n+\n     @property\n     def project_name(self) -> str:\n         return self.project_config.project_name\n \n-    @property\n-    def language(self) -> Language:\n-        return self.project_config.language\n-\n     @classmethod\n     def load(cls, project_root: str | Path, autogenerate: bool = True) -> \"Project\":\n         project_root = Path(project_root).resolve()\n@@ -68,12 +110,42 @@ class Project:\n         project_config = ProjectConfig.load(project_root, autogenerate=autogenerate)\n         return Project(project_root=str(project_root), project_config=project_config)\n \n+    def save_config(self) -> None:\n+        \"\"\"\n+        Saves the current project configuration to disk.\n+        \"\"\"\n+        config_path = os.path.join(self.project_root, self.project_config.rel_path_to_project_yml())\n+        log.info(\"Saving updated project configuration to %s\", config_path)\n+        config_with_comments = ProjectConfig.load_commented_map(config_path)\n+        config_with_comments.update(self.project_config.to_yaml_dict())\n+        save_yaml(config_path, config_with_comments, preserve_comments=True)\n+\n     def path_to_serena_data_folder(self) -> str:\n         return os.path.join(self.project_root, SERENA_MANAGED_DIR_NAME)\n \n     def path_to_project_yml(self) -> str:\n         return os.path.join(self.project_root, self.project_config.rel_path_to_project_yml())\n \n+    def get_activation_message(self) -> str:\n+        \"\"\"\n+        :return: a message providing information about the project upon activation (e.g. programming language, memories, initial prompt)\n+        \"\"\"\n+        if self._is_newly_created:\n+            msg = f\"Created and activated a new project with name '{self.project_name}' at {self.project_root}. \"\n+        else:\n+            msg = f\"The project with name '{self.project_name}' at {self.project_root} is activated.\"\n+        languages_str = \", \".join([lang.value for lang in self.project_config.languages])\n+        msg += f\"\\nProgramming languages: {languages_str}; file encoding: {self.project_config.encoding}\"\n+        memories = self.memories_manager.list_memories()\n+        if memories:\n+            msg += (\n+                f\"\\nAvailable project memories: {json.dumps(memories)}\\n\"\n+                + \"Use the `read_memory` tool to read these memories later if they are relevant to the task.\"\n+            )\n+        if self.project_config.initial_prompt:\n+            msg += f\"\\nAdditional project-specific instructions:\\n {self.project_config.initial_prompt}\"\n+        return msg\n+\n     def read_file(self, relative_path: str) -> str:\n         \"\"\"\n         Reads a file relative to the project root.\n@@ -82,9 +154,7 @@ class Project:\n         :return: the content of the file\n         \"\"\"\n         abs_path = Path(self.project_root) / relative_path\n-        if not abs_path.exists():\n-            raise FileNotFoundError(f\"File not found: {abs_path}\")\n-        return abs_path.read_text(encoding=self.project_config.encoding)\n+        return FileUtils.read_file(str(abs_path), self.project_config.encoding)\n \n     def get_ignore_spec(self) -> pathspec.PathSpec:\n         \"\"\"\n@@ -104,6 +174,12 @@ class Project:\n \n         :return: whether the path should be ignored\n         \"\"\"\n+        # special case, never ignore the project root itself\n+        # If the user ignores hidden files, \".\" might match against the corresponding PathSpec pattern.\n+        # The empty string also points to the project root and should never be ignored.\n+        if str(relative_path) in [\".\", \"\"]:\n+            return False\n+\n         abs_path = os.path.join(self.project_root, relative_path)\n         if not os.path.exists(abs_path):\n             raise FileNotFoundError(f\"File {abs_path} not found, the ignore check cannot be performed\")\n@@ -111,8 +187,13 @@ class Project:\n         # Check file extension if it's a file\n         is_file = os.path.isfile(abs_path)\n         if is_file and ignore_non_source_files:\n-            fn_matcher = self.language.get_source_fn_matcher()\n-            if not fn_matcher.is_relevant_filename(abs_path):\n+            is_file_in_supported_language = False\n+            for language in self.project_config.languages:\n+                fn_matcher = language.get_source_fn_matcher()\n+                if fn_matcher.is_relevant_filename(abs_path):\n+                    is_file_in_supported_language = True\n+                    break\n+            if not is_file_in_supported_language:\n                 return True\n \n         # Create normalized path for consistent handling\n@@ -169,18 +250,22 @@ class Project:\n         abs_path = Path(self.project_root) / relative_path\n         return abs_path.exists()\n \n-    def validate_relative_path(self, relative_path: str) -> None:\n+    def validate_relative_path(self, relative_path: str, require_not_ignored: bool = False) -> None:\n         \"\"\"\n         Validates that the given relative path to an existing file/dir is safe to read or edit,\n-        meaning it's inside the project directory and is not ignored by git.\n+        meaning it's inside the project directory.\n \n         Passing a path to a non-existing file will lead to a `FileNotFoundError`.\n+\n+        :param relative_path: the path to validate, relative to the project root\n+        :param require_not_ignored: if True, the path must not be ignored according to the project's ignore settings\n         \"\"\"\n         if not self.is_path_in_project(relative_path):\n             raise ValueError(f\"{relative_path=} points to path outside of the repository root; cannot access for safety reasons\")\n \n-        if self.is_ignored_path(relative_path):\n-            raise ValueError(f\"Path {relative_path} is ignored; cannot access for safety reasons\")\n+        if require_not_ignored:\n+            if self.is_ignored_path(relative_path):\n+                raise ValueError(f\"Path {relative_path} is ignored; cannot access for safety reasons\")\n \n     def gather_source_files(self, relative_path: str = \"\") -> list[str]:\n         \"\"\"Retrieves relative paths of all source files, optionally limited to the given path\n@@ -244,6 +329,7 @@ class Project:\n             relative_file_paths,\n             pattern,\n             root_path=self.project_root,\n+            file_reader=self.read_file,\n             context_lines_before=context_lines_before,\n             context_lines_after=context_lines_after,\n             paths_include_glob=paths_include_glob,\n@@ -272,35 +358,87 @@ class Project:\n             source_file_path=relative_file_path,\n         )\n \n-    def create_language_server(\n+    def create_language_server_manager(\n         self,\n         log_level: int = logging.INFO,\n         ls_timeout: float | None = DEFAULT_TOOL_TIMEOUT - 5,\n         trace_lsp_communication: bool = False,\n-    ) -> SolidLanguageServer:\n+        ls_specific_settings: dict[Language, Any] | None = None,\n+    ) -> LanguageServerManager:\n         \"\"\"\n-        Create a language server for a project. Note that you will have to start it\n-        before performing any LS operations.\n+        Creates the language server manager for the project, starting one language server per configured programming language.\n \n-        :param project: either a path to the project root or a ProjectConfig instance.\n-            If no project.yml is found, the default project configuration will be used.\n         :param log_level: the log level for the language server\n         :param ls_timeout: the timeout for the language server\n         :param trace_lsp_communication: whether to trace LSP communication\n-        :return: the language server\n+        :param ls_specific_settings: optional LS specific configuration of the language server,\n+            see docstrings in the inits of subclasses of SolidLanguageServer to see what values may be passed.\n+        :return: the language server manager, which is also stored in the project instance\n         \"\"\"\n-        ls_config = LanguageServerConfig(\n-            code_language=self.language,\n-            ignored_paths=self._ignored_patterns,\n+        # if there is an existing instance, stop its language servers first\n+        if self.language_server_manager is not None:\n+            log.info(\"Stopping existing language server manager ...\")\n+            self.language_server_manager.stop_all()\n+            self.language_server_manager = None\n+\n+        log.info(f\"Creating language server manager for {self.project_root}\")\n+        factory = LanguageServerFactory(\n+            project_root=self.project_root,\n+            encoding=self.project_config.encoding,\n+            ignored_patterns=self._ignored_patterns,\n+            ls_timeout=ls_timeout,\n+            ls_specific_settings=ls_specific_settings,\n             trace_lsp_communication=trace_lsp_communication,\n         )\n-        ls_logger = LanguageServerLogger(log_level=log_level)\n-\n-        log.info(f\"Creating language server instance for {self.project_root}.\")\n-        return SolidLanguageServer.create(\n-            ls_config,\n-            ls_logger,\n-            self.project_root,\n-            timeout=ls_timeout,\n-            solidlsp_settings=SolidLSPSettings(solidlsp_dir=SERENA_MANAGED_DIR_IN_HOME, project_data_relative_path=SERENA_MANAGED_DIR_NAME),\n-        )\n+        self.language_server_manager = LanguageServerManager.from_languages(self.project_config.languages, factory)\n+        return self.language_server_manager\n+\n+    def add_language(self, language: Language) -> None:\n+        \"\"\"\n+        Adds a new programming language to the project configuration, starting the corresponding\n+        language server instance if the LS manager is active.\n+        The project configuration is saved to disk after adding the language.\n+\n+        :param language: the programming language to add\n+        \"\"\"\n+        if language in self.project_config.languages:\n+            log.info(f\"Language {language.value} is already present in the project configuration.\")\n+            return\n+\n+        # start the language server (if the LS manager is active)\n+        if self.language_server_manager is None:\n+            log.info(\"Language server manager is not active; skipping language server startup for the new language.\")\n+        else:\n+            log.info(\"Adding and starting the language server for new language %s ...\", language.value)\n+            self.language_server_manager.add_language_server(language)\n+\n+        # update the project configuration\n+        self.project_config.languages.append(language)\n+        self.save_config()\n+\n+    def remove_language(self, language: Language) -> None:\n+        \"\"\"\n+        Removes a programming language from the project configuration, stopping the corresponding\n+        language server instance if the LS manager is active.\n+        The project configuration is saved to disk after removing the language.\n+\n+        :param language: the programming language to remove\n+        \"\"\"\n+        if language not in self.project_config.languages:\n+            log.info(f\"Language {language.value} is not present in the project configuration.\")\n+            return\n+        # update the project configuration\n+        self.project_config.languages.remove(language)\n+        self.save_config()\n+\n+        # stop the language server (if the LS manager is active)\n+        if self.language_server_manager is None:\n+            log.info(\"Language server manager is not active; skipping language server shutdown for the removed language.\")\n+        else:\n+            log.info(\"Removing and stopping the language server for language %s ...\", language.value)\n+            self.language_server_manager.remove_language_server(language)\n+\n+    def shutdown(self, timeout: float = 2.0) -> None:\n+        if self.language_server_manager is not None:\n+            self.language_server_manager.stop_all(save_cache=True, timeout=timeout)\n+            self.language_server_manager = None\n",
    "src/serena/tools/cmd_tools.py": "diff --git a/src/serena/tools/cmd_tools.py b/src/serena/tools/cmd_tools.py\nindex ccacd12..e548903 100644\n--- a/src/serena/tools/cmd_tools.py\n+++ b/src/serena/tools/cmd_tools.py\n@@ -2,6 +2,8 @@\n Tools supporting the execution of (external) commands\n \"\"\"\n \n+import os.path\n+\n from serena.tools import Tool, ToolMarkerCanEdit\n from serena.util.shell import execute_shell_command\n \n@@ -20,7 +22,10 @@ class ExecuteShellCommandTool(Tool, ToolMarkerCanEdit):\n     ) -> str:\n         \"\"\"\n         Execute a shell command and return its output. If there is a memory about suggested commands, read that first.\n-        Never execute unsafe shell commands like `rm -rf /` or similar!\n+        Never execute unsafe shell commands!\n+        IMPORTANT: Do not use this tool to start\n+          * long-running processes (e.g. servers) that are not intended to terminate quickly,\n+          * processes that require user interaction.\n \n         :param command: the shell command to execute\n         :param cwd: the working directory to execute the command in. If None, the project root will be used.\n@@ -30,7 +35,18 @@ class ExecuteShellCommandTool(Tool, ToolMarkerCanEdit):\n             required for the task.\n         :return: a JSON object containing the command's stdout and optionally stderr output\n         \"\"\"\n-        _cwd = cwd or self.get_project_root()\n+        if cwd is None:\n+            _cwd = self.get_project_root()\n+        else:\n+            if os.path.isabs(cwd):\n+                _cwd = cwd\n+            else:\n+                _cwd = os.path.join(self.get_project_root(), cwd)\n+                if not os.path.isdir(_cwd):\n+                    raise FileNotFoundError(\n+                        f\"Specified a relative working directory ({cwd}), but the resulting path is not a directory: {_cwd}\"\n+                    )\n+\n         result = execute_shell_command(command, cwd=_cwd, capture_stderr=capture_stderr)\n         result = result.json()\n         return self._limit_length(result, max_answer_chars)\n",
    "src/serena/tools/config_tools.py": "diff --git a/src/serena/tools/config_tools.py b/src/serena/tools/config_tools.py\nindex 8a3ddeb..45ca01c 100644\n--- a/src/serena/tools/config_tools.py\n+++ b/src/serena/tools/config_tools.py\n@@ -1,38 +1,22 @@\n-import json\n-\n from serena.config.context_mode import SerenaAgentMode\n from serena.tools import Tool, ToolMarkerDoesNotRequireActiveProject, ToolMarkerOptional\n \n \n class ActivateProjectTool(Tool, ToolMarkerDoesNotRequireActiveProject):\n     \"\"\"\n-    Activates a project by name.\n+    Activates a project based on the project name or path.\n     \"\"\"\n \n     def apply(self, project: str) -> str:\n         \"\"\"\n-        Activates the project with the given name.\n+        Activates the project with the given name or path.\n \n         :param project: the name of a registered project to activate or a path to a project directory\n         \"\"\"\n         active_project = self.agent.activate_project_from_path_or_name(project)\n-        if active_project.is_newly_created:\n-            result_str = (\n-                f\"Created and activated a new project with name '{active_project.project_name}' at {active_project.project_root}, language: {active_project.project_config.language.value}. \"\n-                \"You can activate this project later by name.\\n\"\n-                f\"The project's Serena configuration is in {active_project.path_to_project_yml()}. In particular, you may want to edit the project name and the initial prompt.\"\n-            )\n-        else:\n-            result_str = f\"Activated existing project with name '{active_project.project_name}' at {active_project.project_root}, language: {active_project.project_config.language.value}\"\n-\n-        if active_project.project_config.initial_prompt:\n-            result_str += f\"\\nAdditional project information:\\n {active_project.project_config.initial_prompt}\"\n-        result_str += (\n-            f\"\\nAvailable memories:\\n {json.dumps(list(self.memories_manager.list_memories()))}\"\n-            + \"You should not read these memories directly, but rather use the `read_memory` tool to read them later if needed for the task.\"\n-        )\n-        result_str += f\"\\nAvailable tools:\\n {json.dumps(self.agent.get_active_tool_names())}\"\n-        return result_str\n+        result = active_project.get_activation_message()\n+        result += \"\\nIMPORTANT: If you have not yet read the 'Serena Instructions Manual', do it now before continuing!\"\n+        return result\n \n \n class RemoveProjectTool(Tool, ToolMarkerDoesNotRequireActiveProject, ToolMarkerOptional):\n@@ -71,7 +55,7 @@ class SwitchModesTool(Tool, ToolMarkerOptional):\n         return result_str\n \n \n-class GetCurrentConfigTool(Tool, ToolMarkerOptional):\n+class GetCurrentConfigTool(Tool):\n     \"\"\"\n     Prints the current configuration of the agent, including the active and available projects, tools, contexts, and modes.\n     \"\"\"\n",
    "src/serena/tools/file_tools.py": "diff --git a/src/serena/tools/file_tools.py b/src/serena/tools/file_tools.py\nindex e5b1467..d243cd3 100644\n--- a/src/serena/tools/file_tools.py\n+++ b/src/serena/tools/file_tools.py\n@@ -6,12 +6,13 @@ File and file system-related tools, specifically for\n   * editing at the file level\n \"\"\"\n \n-import json\n import os\n import re\n from collections import defaultdict\n+from collections.abc import Callable\n from fnmatch import fnmatch\n from pathlib import Path\n+from typing import Literal\n \n from serena.text_utils import search_files\n from serena.tools import SUCCESS_RESULT, EditedFileContext, Tool, ToolMarkerCanEdit, ToolMarkerOptional\n@@ -36,14 +37,13 @@ class ReadFileTool(Tool):\n             required for the task.\n         :return: the full text of the file at the given relative path\n         \"\"\"\n-        self.project.validate_relative_path(relative_path)\n+        self.project.validate_relative_path(relative_path, require_not_ignored=True)\n \n         result = self.project.read_file(relative_path)\n         result_lines = result.splitlines()\n         if end_line is None:\n             result_lines = result_lines[start_line:]\n         else:\n-            self.lines_read.add_lines_read(relative_path, (start_line, end_line))\n             result_lines = result_lines[start_line : end_line + 1]\n         result = \"\\n\".join(result_lines)\n \n@@ -60,7 +60,7 @@ class CreateTextFileTool(Tool, ToolMarkerCanEdit):\n         Write a new file or overwrite an existing file.\n \n         :param relative_path: the relative path to the file to create\n-        :param content: the (utf-8-encoded) content to write to the file\n+        :param content: the (appropriately encoded) content to write to the file\n         :return: a message indicating success or failure\n         \"\"\"\n         project_root = self.get_project_root()\n@@ -68,18 +68,18 @@ class CreateTextFileTool(Tool, ToolMarkerCanEdit):\n         will_overwrite_existing = abs_path.exists()\n \n         if will_overwrite_existing:\n-            self.project.validate_relative_path(relative_path)\n+            self.project.validate_relative_path(relative_path, require_not_ignored=True)\n         else:\n             assert abs_path.is_relative_to(\n                 self.get_project_root()\n             ), f\"Cannot create file outside of the project directory, got {relative_path=}\"\n \n         abs_path.parent.mkdir(parents=True, exist_ok=True)\n-        abs_path.write_text(content, encoding=\"utf-8\")\n+        abs_path.write_text(content, encoding=self.project.project_config.encoding)\n         answer = f\"File created: {relative_path}.\"\n         if will_overwrite_existing:\n             answer += \" Overwrote existing file.\"\n-        return json.dumps(answer)\n+        return answer\n \n \n class ListDirTool(Tool):\n@@ -87,12 +87,13 @@ class ListDirTool(Tool):\n     Lists files and directories in the given directory (optionally with recursion).\n     \"\"\"\n \n-    def apply(self, relative_path: str, recursive: bool, max_answer_chars: int = -1) -> str:\n+    def apply(self, relative_path: str, recursive: bool, skip_ignored_files: bool = False, max_answer_chars: int = -1) -> str:\n         \"\"\"\n-        Lists all non-gitignored files and directories in the given directory (optionally with recursion).\n+        Lists files and directories in the given directory (optionally with recursion).\n \n         :param relative_path: the relative path to the directory to list; pass \".\" to scan the project root\n         :param recursive: whether to scan subdirectories recursively\n+        :param skip_ignored_files: whether to skip files and directories that are ignored\n         :param max_answer_chars: if the output is longer than this number of characters,\n             no content will be returned. -1 means the default value from the config will be used.\n             Don't adjust unless there is really no other way to get the content required for the task.\n@@ -105,19 +106,19 @@ class ListDirTool(Tool):\n                 \"project_root\": self.get_project_root(),\n                 \"hint\": \"Check if the path is correct relative to the project root\",\n             }\n-            return json.dumps(error_info)\n+            return self._to_json(error_info)\n \n-        self.project.validate_relative_path(relative_path)\n+        self.project.validate_relative_path(relative_path, require_not_ignored=skip_ignored_files)\n \n         dirs, files = scan_directory(\n             os.path.join(self.get_project_root(), relative_path),\n             relative_to=self.get_project_root(),\n             recursive=recursive,\n-            is_ignored_dir=self.project.is_ignored_path,\n-            is_ignored_file=self.project.is_ignored_path,\n+            is_ignored_dir=self.project.is_ignored_path if skip_ignored_files else None,\n+            is_ignored_file=self.project.is_ignored_path if skip_ignored_files else None,\n         )\n \n-        result = json.dumps({\"dirs\": dirs, \"files\": files})\n+        result = self._to_json({\"dirs\": dirs, \"files\": files})\n         return self._limit_length(result, max_answer_chars)\n \n \n@@ -134,7 +135,7 @@ class FindFileTool(Tool):\n         :param relative_path: the relative path to the directory to search in; pass \".\" to scan the project root\n         :return: a JSON object with the list of matching files\n         \"\"\"\n-        self.project.validate_relative_path(relative_path)\n+        self.project.validate_relative_path(relative_path, require_not_ignored=True)\n \n         dir_to_scan = os.path.join(self.get_project_root(), relative_path)\n \n@@ -145,7 +146,7 @@ class FindFileTool(Tool):\n             filename = os.path.basename(abs_path)\n             return not fnmatch(filename, file_mask)\n \n-        dirs, files = scan_directory(\n+        _dirs, files = scan_directory(\n             path=dir_to_scan,\n             recursive=True,\n             is_ignored_dir=self.project.is_ignored_path,\n@@ -153,56 +154,135 @@ class FindFileTool(Tool):\n             relative_to=self.get_project_root(),\n         )\n \n-        result = json.dumps({\"files\": files})\n+        result = self._to_json({\"files\": files})\n         return result\n \n \n-class ReplaceRegexTool(Tool, ToolMarkerCanEdit):\n+class ReplaceContentTool(Tool, ToolMarkerCanEdit):\n     \"\"\"\n-    Replaces content in a file by using regular expressions.\n+    Replaces content in a file (optionally using regular expressions).\n     \"\"\"\n \n     def apply(\n         self,\n         relative_path: str,\n-        regex: str,\n+        needle: str,\n         repl: str,\n+        mode: Literal[\"literal\", \"regex\"],\n         allow_multiple_occurrences: bool = False,\n     ) -> str:\n         r\"\"\"\n-        Replaces one or more occurrences of the given regular expression.\n+        Replaces one or more occurrences of a given pattern in a file with new content.\n+\n         This is the preferred way to replace content in a file whenever the symbol-level\n         tools are not appropriate.\n-        Even large sections of code can be replaced by providing a concise regular expression of\n-        the form \"beginning.*?end-of-text-to-be-replaced\".\n-        Always try to use wildcards to avoid specifying the exact content of the code to be replaced,\n-        especially if it spans several lines.\n \n-        IMPORTANT: REMEMBER TO USE WILDCARDS WHEN APPROPRIATE! I WILL BE VERY UNHAPPY IF YOU WRITE LONG REGEXES WITHOUT USING WILDCARDS INSTEAD!\n+        VERY IMPORTANT: The \"regex\" mode allows very large sections of code to be replaced without fully quoting them!\n+        Use a regex of the form \"beginning.*?end-of-text-to-be-replaced\" to be faster and more economical!\n+        ALWAYS try to use wildcards to avoid specifying the exact content to be replaced,\n+        especially if it spans several lines. Note that you cannot make mistakes, because if the regex should match\n+        multiple occurrences while you disabled `allow_multiple_occurrences`, an error will be returned, and you can retry\n+        with a revised regex.\n+        Therefore, using regex mode with suitable wildcards is usually the best choice!\n \n         :param relative_path: the relative path to the file\n-        :param regex: a Python-style regular expression, matches of which will be replaced.\n-            Dot matches all characters, multi-line matching is enabled.\n-        :param repl: the string to replace the matched content with, which may contain\n-            backreferences like \\1, \\2, etc.\n-            Make sure to escape special characters appropriately, e.g., use `\\\\n` for a literal `\\n`.\n+        :param needle: the string or regex pattern to search for.\n+            If `mode` is \"literal\", this string will be matched exactly.\n+            If `mode` is \"regex\", this string will be treated as a regular expression (syntax of Python's `re` module,\n+            with flags DOTALL and MULTILINE enabled).\n+        :param repl: the replacement string (verbatim).\n+            If mode is \"regex\", the string can contain backreferences to matched groups in the needle regex,\n+            specified using the syntax $!1, $!2, etc. for groups 1, 2, etc.\n+        :param mode: either \"literal\" or \"regex\", specifying how the `needle` parameter is to be interpreted.\n         :param allow_multiple_occurrences: if True, the regex may match multiple occurrences in the file\n             and all of them will be replaced.\n             If this is set to False and the regex matches multiple occurrences, an error will be returned\n             (and you may retry with a revised, more specific regex).\n         \"\"\"\n-        self.project.validate_relative_path(relative_path)\n-        with EditedFileContext(relative_path, self.agent) as context:\n+        return self.replace_content(\n+            relative_path, needle, repl, mode=mode, allow_multiple_occurrences=allow_multiple_occurrences, require_not_ignored=True\n+        )\n+\n+    @staticmethod\n+    def _create_replacement_function(regex_pattern: str, repl_template: str, regex_flags: int) -> Callable[[re.Match], str]:\n+        \"\"\"\n+        Creates a replacement function that validates for ambiguity and handles backreferences.\n+\n+        :param regex_pattern: The regex pattern being used for matching\n+        :param repl_template: The replacement template with $!1, $!2, etc. for backreferences\n+        :param regex_flags: The flags to use when searching (e.g., re.DOTALL | re.MULTILINE)\n+        :return: A function suitable for use with re.sub() or re.subn()\n+        \"\"\"\n+\n+        def validate_and_replace(match: re.Match) -> str:\n+            matched_text = match.group(0)\n+\n+            # For multi-line match, check if the same pattern matches again within the already-matched text,\n+            # rendering the match ambiguous. Typical pattern in the code:\n+            #    <start><other-stuff><start><stuff><end>\n+            # When matching\n+            #    <start>.*?<end>\n+            # this will match the entire span above, while only the suffix may have been intended.\n+            # (See test case for a practical example.)\n+            # To detect this, we check if the same pattern matches again within the matched text,\n+            if \"\\n\" in matched_text and re.search(regex_pattern, matched_text[1:], flags=regex_flags):\n+                raise ValueError(\n+                    \"Match is ambiguous: the search pattern matches multiple overlapping occurrences. \"\n+                    \"Please revise the search pattern to be more specific to avoid ambiguity.\"\n+                )\n+\n+            # Handle backreferences: replace $!1, $!2, etc. with actual matched groups\n+            def expand_backreference(m: re.Match) -> str:\n+                group_num = int(m.group(1))\n+                group_value = match.group(group_num)\n+                return group_value if group_value is not None else m.group(0)\n+\n+            result = re.sub(r\"\\$!(\\d+)\", expand_backreference, repl_template)\n+            return result\n+\n+        return validate_and_replace\n+\n+    def replace_content(\n+        self,\n+        relative_path: str,\n+        needle: str,\n+        repl: str,\n+        mode: Literal[\"literal\", \"regex\"],\n+        allow_multiple_occurrences: bool = False,\n+        require_not_ignored: bool = True,\n+    ) -> str:\n+        \"\"\"\n+        Performs the replacement, with additional options not exposed in the tool.\n+        This function can be used internally by other tools.\n+        \"\"\"\n+        self.project.validate_relative_path(relative_path, require_not_ignored=require_not_ignored)\n+        with EditedFileContext(relative_path, self.create_code_editor()) as context:\n             original_content = context.get_original_content()\n-            updated_content, n = re.subn(regex, repl, original_content, flags=re.DOTALL | re.MULTILINE)\n+\n+            if mode == \"literal\":\n+                regex = re.escape(needle)\n+            elif mode == \"regex\":\n+                regex = needle\n+            else:\n+                raise ValueError(f\"Invalid mode: '{mode}', expected 'literal' or 'regex'.\")\n+\n+            regex_flags = re.DOTALL | re.MULTILINE\n+\n+            # create replacement function with validation and backreference handling\n+            repl_fn = self._create_replacement_function(regex, repl, regex_flags=regex_flags)\n+\n+            # perform replacement\n+            updated_content, n = re.subn(regex, repl_fn, original_content, flags=regex_flags)\n+\n             if n == 0:\n-                return f\"Error: No matches found for regex '{regex}' in file '{relative_path}'.\"\n+                raise ValueError(f\"Error: No matches of search expression found in file '{relative_path}'.\")\n             if not allow_multiple_occurrences and n > 1:\n-                return (\n-                    f\"Error: Regex '{regex}' matches {n} occurrences in file '{relative_path}'. \"\n-                    \"Please revise the regex to be more specific or enable allow_multiple_occurrences if this is expected.\"\n+                raise ValueError(\n+                    f\"Expression matches {n} occurrences in file '{relative_path}'. \"\n+                    \"Please revise the expression to be more specific or enable allow_multiple_occurrences if this is expected.\"\n                 )\n             context.set_updated_content(updated_content)\n+\n         return SUCCESS_RESULT\n \n \n@@ -226,9 +306,6 @@ class DeleteLinesTool(Tool, ToolMarkerCanEdit, ToolMarkerOptional):\n         :param start_line: the 0-based index of the first line to be deleted\n         :param end_line: the 0-based index of the last line to be deleted\n         \"\"\"\n-        if not self.lines_read.were_lines_read(relative_path, (start_line, end_line)):\n-            read_lines_tool = self.agent.get_tool(ReadFileTool)\n-            return f\"Error: Must call `{read_lines_tool.get_name_from_cls()}` first to read exactly the affected lines.\"\n         code_editor = self.create_code_editor()\n         code_editor.delete_lines(relative_path, start_line, end_line)\n         return SUCCESS_RESULT\n@@ -341,9 +418,11 @@ class SearchForPatternTool(Tool):\n         :param context_lines_after: Number of lines of context to include after each match\n         :param paths_include_glob: optional glob pattern specifying files to include in the search.\n             Matches against relative file paths from the project root (e.g., \"*.py\", \"src/**/*.ts\").\n+            Supports standard glob patterns (*, ?, [seq], **, etc.) and brace expansion {a,b,c}.\n             Only matches files, not directories. If left empty, all non-ignored files will be included.\n         :param paths_exclude_glob: optional glob pattern specifying files to exclude from the search.\n             Matches against relative file paths from the project root (e.g., \"*test*\", \"**/*_generated.py\").\n+            Supports standard glob patterns (*, ?, [seq], **, etc.) and brace expansion {a,b,c}.\n             Takes precedence over paths_include_glob. Only matches files, not directories. If left empty, no files are excluded.\n         :param relative_path: only subpaths of this path (relative to the repo root) will be analyzed. If a path to a single\n             file is passed, only that will be searched. The path must exist, otherwise a `FileNotFoundError` is raised.\n@@ -378,7 +457,7 @@ class SearchForPatternTool(Tool):\n             if os.path.isfile(abs_path):\n                 rel_paths_to_search = [relative_path]\n             else:\n-                dirs, rel_paths_to_search = scan_directory(\n+                _dirs, rel_paths_to_search = scan_directory(\n                     path=abs_path,\n                     recursive=True,\n                     is_ignored_dir=self.project.is_ignored_path,\n@@ -390,6 +469,7 @@ class SearchForPatternTool(Tool):\n             matches = search_files(\n                 rel_paths_to_search,\n                 substring_pattern,\n+                file_reader=self.project.read_file,\n                 root_path=self.get_project_root(),\n                 paths_include_glob=paths_include_glob,\n                 paths_exclude_glob=paths_exclude_glob,\n@@ -399,5 +479,5 @@ class SearchForPatternTool(Tool):\n         for match in matches:\n             assert match.source_file_path is not None\n             file_to_matches[match.source_file_path].append(match.to_display_string())\n-        result = json.dumps(file_to_matches)\n+        result = self._to_json(file_to_matches)\n         return self._limit_length(result, max_answer_chars)\n",
    "src/serena/tools/jetbrains_plugin_client.py": "diff --git a/src/serena/tools/jetbrains_plugin_client.py b/src/serena/tools/jetbrains_plugin_client.py\nindex 594b51d..cd31b7b 100644\n--- a/src/serena/tools/jetbrains_plugin_client.py\n+++ b/src/serena/tools/jetbrains_plugin_client.py\n@@ -8,6 +8,7 @@ from pathlib import Path\n from typing import Any, Optional, Self, TypeVar\n \n import requests\n+from requests import Response\n from sensai.util.string import ToStringMixin\n \n from serena.project import Project\n@@ -78,6 +79,7 @@ class JetBrainsPluginClient(ToStringMixin):\n     def _make_request(self, method: str, endpoint: str, data: Optional[dict] = None) -> dict[str, Any]:\n         url = f\"{self.base_url}{endpoint}\"\n \n+        response: Response | None = None\n         try:\n             if method.upper() == \"GET\":\n                 response = self.session.get(url, timeout=self.timeout)\n@@ -100,8 +102,10 @@ class JetBrainsPluginClient(ToStringMixin):\n             raise ConnectionError(f\"Failed to connect to Serena service at {url}: {e}\")\n         except requests.exceptions.Timeout as e:\n             raise ConnectionError(f\"Request to {url} timed out: {e}\")\n-        except requests.exceptions.HTTPError:\n-            raise APIError(f\"API request failed with status {response.status_code}: {response.text}\")\n+        except requests.exceptions.HTTPError as e:\n+            if response is not None:\n+                raise APIError(f\"API request failed with status {response.status_code}: {response.text}\")\n+            raise APIError(f\"API request failed with HTTP error: {e}\")\n         except requests.exceptions.RequestException as e:\n             raise SerenaClientError(f\"Request failed: {e}\")\n \n@@ -129,15 +133,23 @@ class JetBrainsPluginClient(ToStringMixin):\n         return response[\"project_root\"]\n \n     def find_symbol(\n-        self, name_path: str, relative_path: str | None = None, include_body: bool = False, depth: int = 0, include_location: bool = False\n+        self,\n+        name_path: str,\n+        relative_path: str | None = None,\n+        include_body: bool = False,\n+        depth: int = 0,\n+        include_location: bool = False,\n+        search_deps: bool = False,\n     ) -> dict[str, Any]:\n         \"\"\"\n-        Find symbols by name.\n+        Finds symbols by name.\n \n         :param name_path: the name path to match\n         :param relative_path: the relative path to which to restrict the search\n         :param include_body: whether to include symbol body content\n         :param depth: depth of children to include (0 = no children)\n+        :param include_location: whether to include symbol location information\n+        :param search_deps: whether to also search in dependencies\n \n         :return: Dictionary containing 'symbols' list with matching symbols\n         \"\"\"\n@@ -147,12 +159,13 @@ class JetBrainsPluginClient(ToStringMixin):\n             \"includeBody\": include_body,\n             \"depth\": depth,\n             \"includeLocation\": include_location,\n+            \"searchDeps\": search_deps,\n         }\n         return self._make_request(\"POST\", \"/findSymbol\", request_data)\n \n     def find_references(self, name_path: str, relative_path: str) -> dict[str, Any]:\n         \"\"\"\n-        Find references to a symbol.\n+        Finds references to a symbol.\n \n         :param name_path: the name path of the symbol\n         :param relative_path: the relative path\n@@ -168,10 +181,42 @@ class JetBrainsPluginClient(ToStringMixin):\n         request_data = {\"relativePath\": relative_path}\n         return self._make_request(\"POST\", \"/getSymbolsOverview\", request_data)\n \n+    def rename_symbol(\n+        self, name_path: str, relative_path: str, new_name: str, rename_in_comments: bool, rename_in_text_occurrences: bool\n+    ) -> None:\n+        \"\"\"\n+        Renames a symbol.\n+\n+        :param name_path: the name path of the symbol\n+        :param relative_path: the relative path\n+        :param new_name: the new name for the symbol\n+        :param rename_in_comments: whether to rename in comments\n+        :param rename_in_text_occurrences: whether to rename in text occurrences\n+        \"\"\"\n+        request_data = {\n+            \"namePath\": name_path,\n+            \"relativePath\": relative_path,\n+            \"newName\": new_name,\n+            \"renameInComments\": rename_in_comments,\n+            \"renameInTextOccurrences\": rename_in_text_occurrences,\n+        }\n+        self._make_request(\"POST\", \"/renameSymbol\", request_data)\n+\n+    def refresh_file(self, relative_path: str) -> None:\n+        \"\"\"\n+        Triggers a refresh of the given file in the IDE.\n+\n+        :param relative_path: the relative path\n+        \"\"\"\n+        request_data = {\n+            \"relativePath\": relative_path,\n+        }\n+        self._make_request(\"POST\", \"/refreshFile\", request_data)\n+\n     def is_service_available(self) -> bool:\n         try:\n-            response = self.heartbeat()\n-            return response.get(\"status\") == \"OK\"\n+            self.project_root()\n+            return True\n         except (ConnectionError, APIError):\n             return False\n \n",
    "src/serena/tools/jetbrains_tools.py": "diff --git a/src/serena/tools/jetbrains_tools.py b/src/serena/tools/jetbrains_tools.py\nindex db3a97c..e2b84e6 100644\n--- a/src/serena/tools/jetbrains_tools.py\n+++ b/src/serena/tools/jetbrains_tools.py\n@@ -1,79 +1,70 @@\n-import json\n-\n from serena.tools import Tool, ToolMarkerOptional, ToolMarkerSymbolicRead\n from serena.tools.jetbrains_plugin_client import JetBrainsPluginClient\n \n \n class JetBrainsFindSymbolTool(Tool, ToolMarkerSymbolicRead, ToolMarkerOptional):\n     \"\"\"\n-    Performs a global (or local) search for symbols with/containing a given name/substring (optionally filtered by type).\n+    Performs a global (or local) search for symbols using the JetBrains backend\n     \"\"\"\n \n     def apply(\n         self,\n-        name_path: str,\n+        name_path_pattern: str,\n         depth: int = 0,\n         relative_path: str | None = None,\n         include_body: bool = False,\n+        search_deps: bool = False,\n         max_answer_chars: int = -1,\n     ) -> str:\n         \"\"\"\n-        Retrieves information on all symbols/code entities (classes, methods, etc.) based on the given `name_path`,\n-        which represents a pattern for the symbol's path within the symbol tree of a single file.\n-        The returned symbol location can be used for edits or further queries.\n+        Retrieves information on all symbols/code entities (classes, methods, etc.) based on the given name path pattern.\n+        The returned symbol information can be used for edits or further queries.\n         Specify `depth > 0` to retrieve children (e.g., methods of a class).\n \n-        The matching behavior is determined by the structure of `name_path`, which can\n-        either be a simple name (e.g. \"method\") or a name path like \"class/method\" (relative name path)\n-        or \"/class/method\" (absolute name path).\n-        Note that the name path is not a path in the file system but rather a path in the symbol tree\n-        **within a single file**. Thus, file or directory names should never be included in the `name_path`.\n-        For restricting the search to a single file or directory, pass the `relative_path` parameter.\n-        The retrieved symbols' `name_path` attribute will always be composed of symbol names, never file\n-        or directory names.\n+        A name path is a path in the symbol tree *within a source file*.\n+        For example, the method `my_method` defined in class `MyClass` would have the name path `MyClass/my_method`.\n+        If a symbol is overloaded (e.g., in Java), a 0-based index is appended (e.g. \"MyClass/my_method[0]\") to\n+        uniquely identify it.\n \n-        Key aspects of the name path matching behavior:\n-        - The name of the retrieved symbols will match the last segment of `name_path`, while preceding segments\n-          will restrict the search to symbols that have a desired sequence of ancestors.\n-        - If there is no `/` in `name_path`, there is no restriction on the ancestor symbols.\n-          For example, passing `method` will match against all symbols with name paths like `method`,\n-          `class/method`, `class/nested_class/method`, etc.\n-        - If `name_path` contains at least one `/`, the matching is restricted to symbols\n-          with the respective ancestors. For example, passing `class/method` will match against\n-          `class/method` as well as `nested_class/class/method` but not `other_class/method`.\n-        - If `name_path` starts with a `/`, it will be treated as an absolute name path pattern, i.e.\n-          all ancestors are provided and must match.\n-          For example, passing `/class` will match only against top-level symbols named `class` but\n-          will not match `nested_class/class`. Passing `/class/method` will match `class/method` but\n-          not `outer_class/class/method`.\n+        To search for a symbol, you provide a name path pattern that is used to match against name paths.\n+        It can be\n+         * a simple name (e.g. \"method\"), which will match any symbol with that name\n+         * a relative path like \"class/method\", which will match any symbol with that name path suffix\n+         * an absolute name path \"/class/method\" (absolute name path), which requires an exact match of the full name path within the source file.\n+        Append an index `[i]` to match a specific overload only, e.g. \"MyClass/my_method[1]\".\n \n-        :param name_path: The name path pattern to search for, see above for details.\n-        :param depth: Depth to retrieve descendants (e.g., 1 for class methods/attributes).\n-        :param relative_path: Optional. Restrict search to this file or directory.\n-            If None, searches entire codebase.\n+        :param name_path_pattern: the name path matching pattern (see above)\n+        :param depth: depth up to which descendants shall be retrieved (e.g. use 1 to also retrieve immediate children;\n+            for the case where the symbol is a class, this will return its methods).\n+            Default 0.\n+        :param relative_path: Optional. Restrict search to this file or directory. If None, searches entire codebase.\n             If a directory is passed, the search will be restricted to the files in that directory.\n             If a file is passed, the search will be restricted to that file.\n             If you have some knowledge about the codebase, you should use this parameter, as it will significantly\n             speed up the search as well as reduce the number of results.\n         :param include_body: If True, include the symbol's source code. Use judiciously.\n+        :param search_deps: If True, also search in project dependencies (e.g., libraries).\n         :param max_answer_chars: max characters for the JSON result. If exceeded, no content is returned.\n             -1 means the default value from the config will be used.\n         :return: JSON string: a list of symbols (with locations) matching the name.\n         \"\"\"\n+        if relative_path == \".\":\n+            relative_path = None\n         with JetBrainsPluginClient.from_project(self.project) as client:\n             response_dict = client.find_symbol(\n-                name_path=name_path,\n+                name_path=name_path_pattern,\n                 relative_path=relative_path,\n                 depth=depth,\n                 include_body=include_body,\n+                search_deps=search_deps,\n             )\n-            result = json.dumps(response_dict)\n+            result = self._to_json(response_dict)\n         return self._limit_length(result, max_answer_chars)\n \n \n class JetBrainsFindReferencingSymbolsTool(Tool, ToolMarkerSymbolicRead, ToolMarkerOptional):\n     \"\"\"\n-    Finds symbols that reference the given symbol\n+    Finds symbols that reference the given symbol using the JetBrains backend\n     \"\"\"\n \n     def apply(\n@@ -98,13 +89,13 @@ class JetBrainsFindReferencingSymbolsTool(Tool, ToolMarkerSymbolicRead, ToolMark\n                 name_path=name_path,\n                 relative_path=relative_path,\n             )\n-            result = json.dumps(response_dict)\n+            result = self._to_json(response_dict)\n         return self._limit_length(result, max_answer_chars)\n \n \n class JetBrainsGetSymbolsOverviewTool(Tool, ToolMarkerSymbolicRead, ToolMarkerOptional):\n     \"\"\"\n-    Retrieves an overview of the top-level symbols within a specified file\n+    Retrieves an overview of the top-level symbols within a specified file using the JetBrains backend\n     \"\"\"\n \n     def apply(\n@@ -128,5 +119,5 @@ class JetBrainsGetSymbolsOverviewTool(Tool, ToolMarkerSymbolicRead, ToolMarkerOp\n             response_dict = client.get_symbols_overview(\n                 relative_path=relative_path,\n             )\n-            result = json.dumps(response_dict)\n+            result = self._to_json(response_dict)\n         return self._limit_length(result, max_answer_chars)\n",
    "src/serena/tools/memory_tools.py": "diff --git a/src/serena/tools/memory_tools.py b/src/serena/tools/memory_tools.py\nindex f52ae3f..94b6900 100644\n--- a/src/serena/tools/memory_tools.py\n+++ b/src/serena/tools/memory_tools.py\n@@ -1,6 +1,6 @@\n-import json\n+from typing import Literal\n \n-from serena.tools import Tool\n+from serena.tools import ReplaceContentTool, Tool\n \n \n class WriteMemoryTool(Tool):\n@@ -8,19 +8,21 @@ class WriteMemoryTool(Tool):\n     Writes a named memory (for future reference) to Serena's project-specific memory store.\n     \"\"\"\n \n-    def apply(self, memory_name: str, content: str, max_answer_chars: int = -1) -> str:\n+    def apply(self, memory_file_name: str, content: str, max_answer_chars: int = -1) -> str:\n         \"\"\"\n-        Write some information about this project that can be useful for future tasks to a memory in md format.\n+        Write some information (utf-8-encoded) about this project that can be useful for future tasks to a memory in md format.\n         The memory name should be meaningful.\n         \"\"\"\n+        # NOTE: utf-8 encoding is configured in the MemoriesManager\n         if max_answer_chars == -1:\n             max_answer_chars = self.agent.serena_config.default_max_tool_answer_chars\n         if len(content) > max_answer_chars:\n             raise ValueError(\n-                f\"Content for {memory_name} is too long. Max length is {max_answer_chars} characters. \" + \"Please make the content shorter.\"\n+                f\"Content for {memory_file_name} is too long. Max length is {max_answer_chars} characters. \"\n+                + \"Please make the content shorter.\"\n             )\n \n-        return self.memories_manager.save_memory(memory_name, content)\n+        return self.memories_manager.save_memory(memory_file_name, content)\n \n \n class ReadMemoryTool(Tool):\n@@ -47,7 +49,7 @@ class ListMemoriesTool(Tool):\n         \"\"\"\n         List available memories. Any memory can be read using the `read_memory` tool.\n         \"\"\"\n-        return json.dumps(self.memories_manager.list_memories())\n+        return self._to_json(self.memories_manager.list_memories())\n \n \n class DeleteMemoryTool(Tool):\n@@ -62,3 +64,27 @@ class DeleteMemoryTool(Tool):\n         or no longer relevant for the project.\n         \"\"\"\n         return self.memories_manager.delete_memory(memory_file_name)\n+\n+\n+class EditMemoryTool(Tool):\n+    def apply(\n+        self,\n+        memory_file_name: str,\n+        needle: str,\n+        repl: str,\n+        mode: Literal[\"literal\", \"regex\"],\n+    ) -> str:\n+        r\"\"\"\n+        Replaces content matching a regular expression in a memory.\n+\n+        :param memory_file_name: the name of the memory\n+        :param needle: the string or regex pattern to search for.\n+            If `mode` is \"literal\", this string will be matched exactly.\n+            If `mode` is \"regex\", this string will be treated as a regular expression (syntax of Python's `re` module,\n+            with flags DOTALL and MULTILINE enabled).\n+        :param repl: the replacement string (verbatim).\n+        :param mode: either \"literal\" or \"regex\", specifying how the `needle` parameter is to be interpreted.\n+        \"\"\"\n+        replace_content_tool = self.agent.get_tool(ReplaceContentTool)\n+        rel_path = self.memories_manager.get_memory_file_path(memory_file_name).relative_to(self.get_project_root())\n+        return replace_content_tool.replace_content(str(rel_path), needle, repl, mode=mode, require_not_ignored=False)\n",
    "src/serena/tools/symbol_tools.py": "diff --git a/src/serena/tools/symbol_tools.py b/src/serena/tools/symbol_tools.py\nindex 9cbc525..75d0e5c 100644\n--- a/src/serena/tools/symbol_tools.py\n+++ b/src/serena/tools/symbol_tools.py\n@@ -2,8 +2,6 @@\n Language server-related tools\n \"\"\"\n \n-import dataclasses\n-import json\n import os\n from collections.abc import Sequence\n from copy import copy\n@@ -42,7 +40,7 @@ class RestartLanguageServerTool(Tool, ToolMarkerOptional):\n         \"\"\"Use this tool only on explicit user request or after confirmation.\n         It may be necessary to restart the language server if it hangs.\n         \"\"\"\n-        self.agent.reset_language_server()\n+        self.agent.reset_language_server_manager()\n         return SUCCESS_RESULT\n \n \n@@ -51,13 +49,15 @@ class GetSymbolsOverviewTool(Tool, ToolMarkerSymbolicRead):\n     Gets an overview of the top-level symbols defined in a given file.\n     \"\"\"\n \n-    def apply(self, relative_path: str, max_answer_chars: int = -1) -> str:\n+    def apply(self, relative_path: str, depth: int = 0, max_answer_chars: int = -1) -> str:\n         \"\"\"\n         Use this tool to get a high-level understanding of the code symbols in a file.\n         This should be the first tool to call when you want to understand a new file, unless you already know\n         what you are looking for.\n \n         :param relative_path: the relative path to the file to get the overview of\n+        :param depth: depth up to which descendants of top-level symbols shall be retrieved\n+            (e.g. 1 retrieves immediate children). Default 0.\n         :param max_answer_chars: if the overview is longer than this number of characters,\n             no content will be returned. -1 means the default value from the config will be used.\n             Don't adjust unless there is really no other way to get the content required for the task.\n@@ -72,19 +72,20 @@ class GetSymbolsOverviewTool(Tool, ToolMarkerSymbolicRead):\n             raise FileNotFoundError(f\"File or directory {relative_path} does not exist in the project.\")\n         if os.path.isdir(file_path):\n             raise ValueError(f\"Expected a file path, but got a directory path: {relative_path}. \")\n-        result = symbol_retriever.get_symbol_overview(relative_path)[relative_path]\n-        result_json_str = json.dumps([dataclasses.asdict(i) for i in result])\n+        result = symbol_retriever.get_symbol_overview(relative_path, depth=depth)[relative_path]\n+        result_json_str = self._to_json(result)\n         return self._limit_length(result_json_str, max_answer_chars)\n \n \n class FindSymbolTool(Tool, ToolMarkerSymbolicRead):\n     \"\"\"\n-    Performs a global (or local) search for symbols with/containing a given name/substring (optionally filtered by type).\n+    Performs a global (or local) search using the language server backend.\n     \"\"\"\n \n+    # noinspection PyDefaultArgument\n     def apply(\n         self,\n-        name_path: str,\n+        name_path_pattern: str,\n         depth: int = 0,\n         relative_path: str = \"\",\n         include_body: bool = False,\n@@ -94,38 +95,26 @@ class FindSymbolTool(Tool, ToolMarkerSymbolicRead):\n         max_answer_chars: int = -1,\n     ) -> str:\n         \"\"\"\n-        Retrieves information on all symbols/code entities (classes, methods, etc.) based on the given `name_path`,\n-        which represents a pattern for the symbol's path within the symbol tree of a single file.\n-        The returned symbol location can be used for edits or further queries.\n-        Specify `depth > 0` to retrieve children (e.g., methods of a class).\n-\n-        The matching behavior is determined by the structure of `name_path`, which can\n-        either be a simple name (e.g. \"method\") or a name path like \"class/method\" (relative name path)\n-        or \"/class/method\" (absolute name path). Note that the name path is not a path in the file system\n-        but rather a path in the symbol tree **within a single file**. Thus, file or directory names should never\n-        be included in the `name_path`. For restricting the search to a single file or directory,\n-        the `within_relative_path` parameter should be used instead. The retrieved symbols' `name_path` attribute\n-        will always be composed of symbol names, never file or directory names.\n-\n-        Key aspects of the name path matching behavior:\n-        - Trailing slashes in `name_path` play no role and are ignored.\n-        - The name of the retrieved symbols will match (either exactly or as a substring)\n-          the last segment of `name_path`, while other segments will restrict the search to symbols that\n-          have a desired sequence of ancestors.\n-        - If there is no starting or intermediate slash in `name_path`, there is no\n-          restriction on the ancestor symbols. For example, passing `method` will match\n-          against symbols with name paths like `method`, `class/method`, `class/nested_class/method`, etc.\n-        - If `name_path` contains a `/` but doesn't start with a `/`, the matching is restricted to symbols\n-          with the same ancestors as the last segment of `name_path`. For example, passing `class/method` will match against\n-          `class/method` as well as `nested_class/class/method` but not `method`.\n-        - If `name_path` starts with a `/`, it will be treated as an absolute name path pattern, meaning\n-          that the first segment of it must match the first segment of the symbol's name path.\n-          For example, passing `/class` will match only against top-level symbols like `class` but not against `nested_class/class`.\n-          Passing `/class/method` will match against `class/method` but not `nested_class/class/method` or `method`.\n-\n-\n-        :param name_path: The name path pattern to search for, see above for details.\n-        :param depth: Depth to retrieve descendants (e.g., 1 for class methods/attributes).\n+        Retrieves information on all symbols/code entities (classes, methods, etc.) based on the given name path pattern.\n+        The returned symbol information can be used for edits or further queries.\n+        Specify `depth > 0` to also retrieve children/descendants (e.g., methods of a class).\n+\n+        A name path is a path in the symbol tree *within a source file*.\n+        For example, the method `my_method` defined in class `MyClass` would have the name path `MyClass/my_method`.\n+        If a symbol is overloaded (e.g., in Java), a 0-based index is appended (e.g. \"MyClass/my_method[0]\") to\n+        uniquely identify it.\n+\n+        To search for a symbol, you provide a name path pattern that is used to match against name paths.\n+        It can be\n+         * a simple name (e.g. \"method\"), which will match any symbol with that name\n+         * a relative path like \"class/method\", which will match any symbol with that name path suffix\n+         * an absolute name path \"/class/method\" (absolute name path), which requires an exact match of the full name path within the source file.\n+        Append an index `[i]` to match a specific overload only, e.g. \"MyClass/my_method[1]\".\n+\n+        :param name_path_pattern: the name path matching pattern (see above)\n+        :param depth: depth up to which descendants shall be retrieved (e.g. use 1 to also retrieve immediate children;\n+            for the case where the symbol is a class, this will return its methods).\n+            Default 0.\n         :param relative_path: Optional. Restrict search to this file or directory. If None, searches entire codebase.\n             If a directory is passed, the search will be restricted to the files in that directory.\n             If a file is passed, the search will be restricted to that file.\n@@ -139,7 +128,8 @@ class FindSymbolTool(Tool, ToolMarkerSymbolicRead):\n             If not provided, all kinds are included.\n         :param exclude_kinds: Optional. List of LSP symbol kind integers to exclude. Takes precedence over `include_kinds`.\n             If not provided, no kinds are excluded.\n-        :param substring_matching: If True, use substring matching for the last segment of `name`.\n+        :param substring_matching: If True, use substring matching for the last element of the pattern, such that\n+            \"Foo/get\" would match \"Foo/getValue\" and \"Foo/getData\".\n         :param max_answer_chars: Max characters for the JSON result. If exceeded, no content is returned.\n             -1 means the default value from the config will be used.\n         :return: a list of symbols (with locations) matching the name.\n@@ -147,24 +137,24 @@ class FindSymbolTool(Tool, ToolMarkerSymbolicRead):\n         parsed_include_kinds: Sequence[SymbolKind] | None = [SymbolKind(k) for k in include_kinds] if include_kinds else None\n         parsed_exclude_kinds: Sequence[SymbolKind] | None = [SymbolKind(k) for k in exclude_kinds] if exclude_kinds else None\n         symbol_retriever = self.create_language_server_symbol_retriever()\n-        symbols = symbol_retriever.find_by_name(\n-            name_path,\n-            include_body=include_body,\n+        symbols = symbol_retriever.find(\n+            name_path_pattern,\n             include_kinds=parsed_include_kinds,\n             exclude_kinds=parsed_exclude_kinds,\n             substring_matching=substring_matching,\n             within_relative_path=relative_path,\n         )\n         symbol_dicts = [_sanitize_symbol_dict(s.to_dict(kind=True, location=True, depth=depth, include_body=include_body)) for s in symbols]\n-        result = json.dumps(symbol_dicts)\n+        result = self._to_json(symbol_dicts)\n         return self._limit_length(result, max_answer_chars)\n \n \n class FindReferencingSymbolsTool(Tool, ToolMarkerSymbolicRead):\n     \"\"\"\n-    Finds symbols that reference the symbol at the given location (optionally filtered by type).\n+    Finds symbols that reference the given symbol using the language server backend\n     \"\"\"\n \n+    # noinspection PyDefaultArgument\n     def apply(\n         self,\n         name_path: str,\n@@ -208,13 +198,13 @@ class FindReferencingSymbolsTool(Tool, ToolMarkerSymbolicRead):\n                 )\n                 ref_dict[\"content_around_reference\"] = content_around_ref.to_display_string()\n             reference_dicts.append(ref_dict)\n-        result = json.dumps(reference_dicts)\n+        result = self._to_json(reference_dicts)\n         return self._limit_length(result, max_answer_chars)\n \n \n class ReplaceSymbolBodyTool(Tool, ToolMarkerSymbolicEdit):\n     \"\"\"\n-    Replaces the full definition of a symbol.\n+    Replaces the full definition of a symbol using the language server backend.\n     \"\"\"\n \n     def apply(\n@@ -226,10 +216,15 @@ class ReplaceSymbolBodyTool(Tool, ToolMarkerSymbolicEdit):\n         r\"\"\"\n         Replaces the body of the symbol with the given `name_path`.\n \n+        The tool shall be used to replace symbol bodies that have been previously retrieved\n+        (e.g. via `find_symbol`).\n+        IMPORTANT: Do not use this tool if you do not know what exactly constitutes the body of the symbol.\n+\n         :param name_path: for finding the symbol to replace, same logic as in the `find_symbol` tool.\n         :param relative_path: the relative path to the file containing the symbol\n-        :param body: the new symbol body. Important: Begin directly with the symbol definition and provide no\n-            leading indentation for the first line (but do indent the rest of the body according to the context).\n+        :param body: the new symbol body. The symbol body is the definition of a symbol\n+            in the programming language, including e.g. the signature line for functions.\n+            IMPORTANT: The body does NOT include any preceding docstrings/comments or imports, in particular.\n         \"\"\"\n         code_editor = self.create_code_editor()\n         code_editor.replace_body(\n@@ -288,3 +283,29 @@ class InsertBeforeSymbolTool(Tool, ToolMarkerSymbolicEdit):\n         code_editor = self.create_code_editor()\n         code_editor.insert_before_symbol(name_path, relative_file_path=relative_path, body=body)\n         return SUCCESS_RESULT\n+\n+\n+class RenameSymbolTool(Tool, ToolMarkerSymbolicEdit):\n+    \"\"\"\n+    Renames a symbol throughout the codebase using language server refactoring capabilities.\n+    \"\"\"\n+\n+    def apply(\n+        self,\n+        name_path: str,\n+        relative_path: str,\n+        new_name: str,\n+    ) -> str:\n+        \"\"\"\n+        Renames the symbol with the given `name_path` to `new_name` throughout the entire codebase.\n+        Note: for languages with method overloading, like Java, name_path may have to include a method's\n+        signature to uniquely identify a method.\n+\n+        :param name_path: name path of the symbol to rename (definitions in the `find_symbol` tool apply)\n+        :param relative_path: the relative path to the file containing the symbol to rename\n+        :param new_name: the new name for the symbol\n+        :return: result summary indicating success or failure\n+        \"\"\"\n+        code_editor = self.create_code_editor()\n+        status_message = code_editor.rename_symbol(name_path, relative_file_path=relative_path, new_name=new_name)\n+        return status_message\n",
    "src/serena/tools/tools_base.py": "diff --git a/src/serena/tools/tools_base.py b/src/serena/tools/tools_base.py\nindex 46afb36..879f818 100644\n--- a/src/serena/tools/tools_base.py\n+++ b/src/serena/tools/tools_base.py\n@@ -1,5 +1,5 @@\n import inspect\n-import os\n+import json\n from abc import ABC\n from collections.abc import Iterable\n from dataclasses import dataclass\n@@ -10,7 +10,7 @@ from mcp.server.fastmcp.utilities.func_metadata import FuncMetadata, func_metada\n from sensai.util import logging\n from sensai.util.string import dict_string\n \n-from serena.project import Project\n+from serena.project import MemoriesManager, Project\n from serena.prompt_factory import PromptFactory\n from serena.symbol import LanguageServerSymbolRetriever\n from serena.util.class_decorators import singleton\n@@ -18,7 +18,7 @@ from serena.util.inspection import iter_subclasses\n from solidlsp.ls_exceptions import SolidLSPException\n \n if TYPE_CHECKING:\n-    from serena.agent import LinesRead, MemoriesManager, SerenaAgent\n+    from serena.agent import SerenaAgent\n     from serena.code_editor import CodeEditor\n \n log = logging.getLogger(__name__)\n@@ -42,15 +42,13 @@ class Component(ABC):\n \n     @property\n     def memories_manager(self) -> \"MemoriesManager\":\n-        assert self.agent.memories_manager is not None\n-        return self.agent.memories_manager\n+        return self.project.memories_manager\n \n     def create_language_server_symbol_retriever(self) -> LanguageServerSymbolRetriever:\n         if not self.agent.is_using_language_server():\n             raise Exception(\"Cannot create LanguageServerSymbolRetriever; agent is not in language server mode.\")\n-        language_server = self.agent.language_server\n-        assert language_server is not None\n-        return LanguageServerSymbolRetriever(language_server, agent=self.agent)\n+        language_server_manager = self.agent.get_language_server_manager_or_raise()\n+        return LanguageServerSymbolRetriever(language_server_manager, agent=self.agent)\n \n     @property\n     def project(self) -> Project:\n@@ -64,11 +62,6 @@ class Component(ABC):\n         else:\n             return JetBrainsCodeEditor(project=self.project, agent=self.agent)\n \n-    @property\n-    def lines_read(self) -> \"LinesRead\":\n-        assert self.agent.lines_read is not None\n-        return self.agent.lines_read\n-\n \n class ToolMarker:\n     \"\"\"\n@@ -245,33 +238,39 @@ class Tool(Component):\n             try:\n                 # check whether the tool requires an active project and language server\n                 if not isinstance(self, ToolMarkerDoesNotRequireActiveProject):\n-                    if self.agent._active_project is None:\n+                    if self.agent.get_active_project() is None:\n                         return (\n-                            \"Error: No active project. Ask to user to select a project from this list: \"\n+                            \"Error: No active project. Ask the user to provide the project path or to select a project from this list of known projects: \"\n                             + f\"{self.agent.serena_config.project_names}\"\n                         )\n-                    if self.agent.is_using_language_server() and not self.agent.is_language_server_running():\n-                        log.info(\"Language server is not running. Starting it ...\")\n-                        self.agent.reset_language_server()\n \n                 # apply the actual tool\n                 try:\n                     result = apply_fn(**kwargs)\n                 except SolidLSPException as e:\n                     if e.is_language_server_terminated():\n-                        log.error(f\"Language server terminated while executing tool ({e}). Restarting the language server and retrying ...\")\n-                        self.agent.reset_language_server()\n-                        result = apply_fn(**kwargs)\n+                        affected_language = e.get_affected_language()\n+                        if affected_language is not None:\n+                            log.error(\n+                                f\"Language server terminated while executing tool ({e}). Restarting the language server and retrying ...\"\n+                            )\n+                            self.agent.get_language_server_manager_or_raise().restart_language_server(affected_language)\n+                            result = apply_fn(**kwargs)\n+                        else:\n+                            log.error(\n+                                f\"Language server terminated while executing tool ({e}), but affected language is unknown. Not retrying.\"\n+                            )\n+                            raise\n                     else:\n                         raise\n \n                 # record tool usage\n-                self.agent.record_tool_usage_if_enabled(kwargs, result, self)\n+                self.agent.record_tool_usage(kwargs, result, self)\n \n             except Exception as e:\n                 if not catch_exceptions:\n                     raise\n-                msg = f\"Error executing tool: {e}\"\n+                msg = f\"Error executing tool: {e.__class__.__name__} - {e}\"\n                 log.error(f\"Error executing tool: {e}\", exc_info=e)\n                 result = msg\n \n@@ -279,15 +278,26 @@ class Tool(Component):\n                 log.info(f\"Result: {result}\")\n \n             try:\n-                if self.agent.language_server is not None:\n-                    self.agent.language_server.save_cache()\n+                ls_manager = self.agent.get_language_server_manager()\n+                if ls_manager is not None:\n+                    ls_manager.save_all_caches()\n             except Exception as e:\n                 log.error(f\"Error saving language server cache: {e}\")\n \n             return result\n \n-        future = self.agent.issue_task(task, name=self.__class__.__name__)\n-        return future.result(timeout=self.agent.serena_config.tool_timeout)\n+        # execute the tool in the agent's task executor, with timeout\n+        try:\n+            task_exec = self.agent.issue_task(task, name=self.__class__.__name__)\n+            return task_exec.result(timeout=self.agent.serena_config.tool_timeout)\n+        except Exception as e:  # typically TimeoutError (other exceptions caught in task)\n+            msg = f\"Error: {e.__class__.__name__} - {e}\"\n+            log.error(msg)\n+            return msg\n+\n+    @staticmethod\n+    def _to_json(x: Any) -> str:\n+        return json.dumps(x, ensure_ascii=False)\n \n \n class EditedFileContext:\n@@ -299,24 +309,23 @@ class EditedFileContext:\n     When exiting the context without an exception, the updated content will be written back to the file.\n     \"\"\"\n \n-    def __init__(self, relative_path: str, agent: \"SerenaAgent\"):\n-        self._project = agent.get_active_project()\n-        assert self._project is not None\n-        self._abs_path = os.path.join(self._project.project_root, relative_path)\n-        if not os.path.isfile(self._abs_path):\n-            raise FileNotFoundError(f\"File {self._abs_path} does not exist.\")\n-        with open(self._abs_path, encoding=self._project.project_config.encoding) as f:\n-            self._original_content = f.read()\n-        self._updated_content: str | None = None\n+    def __init__(self, relative_path: str, code_editor: \"CodeEditor\"):\n+        self._relative_path = relative_path\n+        self._code_editor = code_editor\n+        self._edited_file: CodeEditor.EditedFile | None = None\n+        self._edited_file_context: Any = None\n \n     def __enter__(self) -> Self:\n+        self._edited_file_context = self._code_editor.edited_file_context(self._relative_path)\n+        self._edited_file = self._edited_file_context.__enter__()\n         return self\n \n     def get_original_content(self) -> str:\n         \"\"\"\n         :return: the original content of the file before any modifications.\n         \"\"\"\n-        return self._original_content\n+        assert self._edited_file is not None\n+        return self._edited_file.get_contents()\n \n     def set_updated_content(self, content: str) -> None:\n         \"\"\"\n@@ -325,16 +334,12 @@ class EditedFileContext:\n \n         :param content: the updated content of the file\n         \"\"\"\n-        self._updated_content = content\n+        assert self._edited_file is not None\n+        self._edited_file.set_contents(content)\n \n     def __exit__(self, exc_type: type[BaseException] | None, exc_value: BaseException | None, traceback: TracebackType | None) -> None:\n-        if self._updated_content is not None and exc_type is None:\n-            assert self._project is not None\n-            with open(self._abs_path, \"w\", encoding=self._project.project_config.encoding) as f:\n-                f.write(self._updated_content)\n-            log.info(f\"Updated content written to {self._abs_path}\")\n-            # Language servers should automatically detect the change and update its state accordingly.\n-            # If they do not, we may have to add a call to notify it.\n+        assert self._edited_file_context is not None\n+        self._edited_file_context.__exit__(exc_type, exc_value, traceback)\n \n \n @dataclass(kw_only=True)\n",
    "src/serena/tools/workflow_tools.py": "diff --git a/src/serena/tools/workflow_tools.py b/src/serena/tools/workflow_tools.py\nindex be78d03..a3a5810 100644\n--- a/src/serena/tools/workflow_tools.py\n+++ b/src/serena/tools/workflow_tools.py\n@@ -16,8 +16,7 @@ class CheckOnboardingPerformedTool(Tool):\n     def apply(self) -> str:\n         \"\"\"\n         Checks whether project onboarding was already performed.\n-        You should always call this tool before beginning to actually work on the project/after activating a project,\n-        but after calling the initial instructions tool.\n+        You should always call this tool before beginning to actually work on the project/after activating a project.\n         \"\"\"\n         from .memory_tools import ListMemoriesTool\n \n@@ -122,18 +121,18 @@ class PrepareForNewConversationTool(Tool):\n         return self.prompt_factory.create_prepare_for_new_conversation()\n \n \n-class InitialInstructionsTool(Tool, ToolMarkerDoesNotRequireActiveProject, ToolMarkerOptional):\n+class InitialInstructionsTool(Tool, ToolMarkerDoesNotRequireActiveProject):\n     \"\"\"\n-    Gets the initial instructions for the current project.\n-    Should only be used in settings where the system prompt cannot be set,\n-    e.g. in clients you have no control over, like Claude Desktop.\n+    Provides instructions on how to use the Serena toolbox.\n+    Should only be used in settings where the system prompt is not read automatically by the client.\n+\n+    NOTE: Some MCP clients (including Claude Desktop) do not read the system prompt automatically!\n     \"\"\"\n \n     def apply(self) -> str:\n         \"\"\"\n-        Get the initial instructions for the current coding project.\n-        If you haven't received instructions on how to use Serena's tools in the system prompt,\n-        you should always call this tool before starting to work (including using any other tool) on any programming task,\n-        the only exception being when you are asked to call `activate_project`, which you should then call before.\n+        Provides the 'Serena Instructions Manual', which contains essential information on how to use the Serena toolbox.\n+        IMPORTANT: If you have not yet read the manual, call this tool immediately after you are given your task by the user,\n+        as it will critically inform you!\n         \"\"\"\n         return self.agent.create_system_prompt()\n"
  },
  "total_upstream_changes": 311,
  "target_directory_changes": 12
}